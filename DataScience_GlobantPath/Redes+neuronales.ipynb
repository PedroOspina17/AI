{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism', 'soc.religion.christian', \n",
    "              'comp.graphics', 'sci.med']\n",
    "\n",
    "twenty_train = fetch_20newsgroups(subset='train', \n",
    "                                  categories=categories, \n",
    "                                  shuffle=True, random_state=42)\n",
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test',\n",
    "                                 categories=categories, \n",
    "                                 shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer()\n",
    "X_train = tf_idf.fit_transform(twenty_train.data)\n",
    "X_test = tf_idf.transform(twenty_test.data)\n",
    "y_train = twenty_train.target\n",
    "y_test = twenty_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
       "      max_iter=None, n_iter=None, n_jobs=1, penalty=None, random_state=0,\n",
       "      shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "clf = Perceptron()\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91411451398135823"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(10,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(10,), random_state=42)\n",
    "mlp_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93009320905459392"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = mlp_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                572624    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 572,964\n",
      "Trainable params: 572,964\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(max_features,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(4, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1805 samples, validate on 452 samples\n",
      "Epoch 1/50\n",
      "1805/1805 [==============================] - 2s 1ms/step - loss: 1.3770 - acc: 0.4100 - val_loss: 1.3506 - val_acc: 0.5265\n",
      "Epoch 2/50\n",
      "1805/1805 [==============================] - 2s 861us/step - loss: 1.3189 - acc: 0.7983 - val_loss: 1.2971 - val_acc: 0.8186\n",
      "Epoch 3/50\n",
      "1805/1805 [==============================] - 1s 828us/step - loss: 1.2526 - acc: 0.9573 - val_loss: 1.2504 - val_acc: 0.8739\n",
      "Epoch 4/50\n",
      "1805/1805 [==============================] - 1s 825us/step - loss: 1.1919 - acc: 0.9795 - val_loss: 1.2054 - val_acc: 0.9137\n",
      "Epoch 5/50\n",
      "1805/1805 [==============================] - 1s 672us/step - loss: 1.1317 - acc: 0.9861 - val_loss: 1.1611 - val_acc: 0.9115\n",
      "Epoch 6/50\n",
      "1805/1805 [==============================] - 1s 749us/step - loss: 1.0714 - acc: 0.9911 - val_loss: 1.1153 - val_acc: 0.9204\n",
      "Epoch 7/50\n",
      "1805/1805 [==============================] - 2s 850us/step - loss: 1.0107 - acc: 0.9928 - val_loss: 1.0681 - val_acc: 0.9270\n",
      "Epoch 8/50\n",
      "1805/1805 [==============================] - 2s 989us/step - loss: 0.9498 - acc: 0.9934 - val_loss: 1.0215 - val_acc: 0.9358\n",
      "Epoch 9/50\n",
      "1805/1805 [==============================] - 2s 912us/step - loss: 0.8895 - acc: 0.9939 - val_loss: 0.9746 - val_acc: 0.9358\n",
      "Epoch 10/50\n",
      "1805/1805 [==============================] - 2s 875us/step - loss: 0.8295 - acc: 0.9950 - val_loss: 0.9287 - val_acc: 0.9381\n",
      "Epoch 11/50\n",
      "1805/1805 [==============================] - 1s 754us/step - loss: 0.7704 - acc: 0.9956 - val_loss: 0.8836 - val_acc: 0.9381\n",
      "Epoch 12/50\n",
      "1805/1805 [==============================] - 1s 714us/step - loss: 0.7132 - acc: 0.9967 - val_loss: 0.8379 - val_acc: 0.9447\n",
      "Epoch 13/50\n",
      "1805/1805 [==============================] - 1s 699us/step - loss: 0.6572 - acc: 0.9961 - val_loss: 0.7929 - val_acc: 0.9447\n",
      "Epoch 14/50\n",
      "1805/1805 [==============================] - 1s 691us/step - loss: 0.6034 - acc: 0.9961 - val_loss: 0.7486 - val_acc: 0.9447\n",
      "Epoch 15/50\n",
      "1805/1805 [==============================] - 1s 752us/step - loss: 0.5517 - acc: 0.9972 - val_loss: 0.7065 - val_acc: 0.9491\n",
      "Epoch 16/50\n",
      "1805/1805 [==============================] - 2s 879us/step - loss: 0.5026 - acc: 0.9989 - val_loss: 0.6654 - val_acc: 0.9513\n",
      "Epoch 17/50\n",
      "1805/1805 [==============================] - 1s 828us/step - loss: 0.4561 - acc: 0.9989 - val_loss: 0.6247 - val_acc: 0.9513\n",
      "Epoch 18/50\n",
      "1805/1805 [==============================] - 2s 841us/step - loss: 0.4123 - acc: 0.9989 - val_loss: 0.5883 - val_acc: 0.9513\n",
      "Epoch 19/50\n",
      "1805/1805 [==============================] - 1s 765us/step - loss: 0.3714 - acc: 0.9989 - val_loss: 0.5505 - val_acc: 0.9558\n",
      "Epoch 20/50\n",
      "1805/1805 [==============================] - 1s 792us/step - loss: 0.3335 - acc: 0.9994 - val_loss: 0.5164 - val_acc: 0.9535\n",
      "Epoch 21/50\n",
      "1805/1805 [==============================] - 1s 793us/step - loss: 0.2985 - acc: 0.9994 - val_loss: 0.4848 - val_acc: 0.9535\n",
      "Epoch 22/50\n",
      "1805/1805 [==============================] - 1s 798us/step - loss: 0.2666 - acc: 0.9994 - val_loss: 0.4525 - val_acc: 0.9558\n",
      "Epoch 23/50\n",
      "1805/1805 [==============================] - 1s 788us/step - loss: 0.2371 - acc: 0.9994 - val_loss: 0.4252 - val_acc: 0.9558\n",
      "Epoch 24/50\n",
      "1805/1805 [==============================] - 1s 824us/step - loss: 0.2105 - acc: 0.9994 - val_loss: 0.3979 - val_acc: 0.9535\n",
      "Epoch 25/50\n",
      "1805/1805 [==============================] - 1s 779us/step - loss: 0.1866 - acc: 0.9994 - val_loss: 0.3730 - val_acc: 0.9580\n",
      "Epoch 26/50\n",
      "1805/1805 [==============================] - 1s 788us/step - loss: 0.1647 - acc: 0.9994 - val_loss: 0.3498 - val_acc: 0.9602\n",
      "Epoch 27/50\n",
      "1805/1805 [==============================] - 1s 768us/step - loss: 0.1452 - acc: 0.9994 - val_loss: 0.3278 - val_acc: 0.9624\n",
      "Epoch 28/50\n",
      "1805/1805 [==============================] - 2s 949us/step - loss: 0.1276 - acc: 0.9994 - val_loss: 0.3078 - val_acc: 0.9624\n",
      "Epoch 29/50\n",
      "1805/1805 [==============================] - 2s 1ms/step - loss: 0.1121 - acc: 0.9994 - val_loss: 0.2893 - val_acc: 0.9646\n",
      "Epoch 30/50\n",
      "1805/1805 [==============================] - 1s 804us/step - loss: 0.0983 - acc: 0.9994 - val_loss: 0.2716 - val_acc: 0.9668\n",
      "Epoch 31/50\n",
      "1805/1805 [==============================] - 1s 722us/step - loss: 0.0860 - acc: 1.0000 - val_loss: 0.2559 - val_acc: 0.9690\n",
      "Epoch 32/50\n",
      "1805/1805 [==============================] - 2s 1ms/step - loss: 0.0751 - acc: 1.0000 - val_loss: 0.2417 - val_acc: 0.9690\n",
      "Epoch 33/50\n",
      "1805/1805 [==============================] - 2s 1ms/step - loss: 0.0655 - acc: 1.0000 - val_loss: 0.2282 - val_acc: 0.9690\n",
      "Epoch 34/50\n",
      "1805/1805 [==============================] - 2s 1ms/step - loss: 0.0571 - acc: 1.0000 - val_loss: 0.2149 - val_acc: 0.9735\n",
      "Epoch 35/50\n",
      "1805/1805 [==============================] - 2s 872us/step - loss: 0.0497 - acc: 1.0000 - val_loss: 0.2039 - val_acc: 0.9735\n",
      "Epoch 36/50\n",
      "1805/1805 [==============================] - 2s 868us/step - loss: 0.0433 - acc: 1.0000 - val_loss: 0.1926 - val_acc: 0.9735\n",
      "Epoch 37/50\n",
      "1805/1805 [==============================] - 1s 830us/step - loss: 0.0376 - acc: 1.0000 - val_loss: 0.1831 - val_acc: 0.9735\n",
      "Epoch 38/50\n",
      "1805/1805 [==============================] - 2s 870us/step - loss: 0.0326 - acc: 1.0000 - val_loss: 0.1744 - val_acc: 0.9735\n",
      "Epoch 39/50\n",
      "1805/1805 [==============================] - 1s 812us/step - loss: 0.0283 - acc: 1.0000 - val_loss: 0.1660 - val_acc: 0.9735\n",
      "Epoch 40/50\n",
      "1805/1805 [==============================] - 1s 792us/step - loss: 0.0246 - acc: 1.0000 - val_loss: 0.1587 - val_acc: 0.9712\n",
      "Epoch 41/50\n",
      "1805/1805 [==============================] - 1s 784us/step - loss: 0.0213 - acc: 1.0000 - val_loss: 0.1512 - val_acc: 0.9735\n",
      "Epoch 42/50\n",
      "1805/1805 [==============================] - 2s 913us/step - loss: 0.0184 - acc: 1.0000 - val_loss: 0.1440 - val_acc: 0.9712\n",
      "Epoch 43/50\n",
      "1805/1805 [==============================] - 1s 807us/step - loss: 0.0159 - acc: 1.0000 - val_loss: 0.1390 - val_acc: 0.9712\n",
      "Epoch 44/50\n",
      "1805/1805 [==============================] - 1s 729us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.1333 - val_acc: 0.9712\n",
      "Epoch 45/50\n",
      "1805/1805 [==============================] - 1s 673us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.1277 - val_acc: 0.9712\n",
      "Epoch 46/50\n",
      "1805/1805 [==============================] - 2s 938us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.1234 - val_acc: 0.9712\n",
      "Epoch 47/50\n",
      "1805/1805 [==============================] - 1s 781us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.1192 - val_acc: 0.9712\n",
      "Epoch 48/50\n",
      "1805/1805 [==============================] - 1s 689us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.1156 - val_acc: 0.9712\n",
      "Epoch 49/50\n",
      "1805/1805 [==============================] - 2s 1ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.1115 - val_acc: 0.9712\n",
      "Epoch 50/50\n",
      "1805/1805 [==============================] - 2s 1ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.1077 - val_acc: 0.9712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a0f936128>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,dummy_y,batch_size=512,epochs=50,verbose=1,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = model.predict_classes(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.922769640479\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
