{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text manipulation (Preprocessing and Modeling)\n",
    "\n",
    "- Python String Module and str.methods\n",
    "- Python Regular Expressions\n",
    "- NLTK\n",
    "- Gensim\n",
    "- spaCy\n",
    "\n",
    "**Why is it important?**\n",
    "\n",
    "This is the main task when tou are working with NLP.  Some applications that you could do with NLP are:\n",
    "\n",
    "* Part-of-speech tagging\n",
    "* Named Entity Recognition NER\n",
    "* Question answering\n",
    "* Speech recognition\n",
    "* Text-to-speech and Speech-to-text\n",
    "* Topic modeling\n",
    "* Sentiment classification\n",
    "* Language modeling\n",
    "* Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python String Module and str.methods\n",
    "\n",
    " \n",
    "- Codec registry and base classes [codecs](https://docs.python.org/3/library/codecs.html#standard-encodings)\n",
    "- Common string operations [string module](https://docs.python.org/3/library/string.html)\n",
    "- String Methods [str.methods](https://docs.python.org/3/library/stdtypes.html#text-sequence-type-str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from string import Formatter\n",
    "from string import Template\n",
    "\n",
    "# String constants\n",
    "print('ascii_letters: ',string.ascii_letters)\n",
    "print('ascii_lowercase: ',string.ascii_lowercase)\n",
    "print('ascii_uppercase: ',string.ascii_uppercase)\n",
    "print('digits: ',string.digits)\n",
    "print('hexdigits: ',string.hexdigits)\n",
    "print('whitespace: ',string.whitespace)  # ' \\t\\n\\r\\x0b\\x0c'\n",
    "print('punctuation: ',string.punctuation)\n",
    "print('printable: ',string.printable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom String Formatting\n",
    "# Format String Syntax\n",
    "formatter = Formatter()\n",
    "print(formatter.format('{website}', website='DS4A'))\n",
    "print(formatter.format('{} {website}', 'Welcome to', website='DS4A'))\n",
    "# format() behaves in similar manner\n",
    "print('{} {website}'.format('Welcome to', website='DS4A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Template strings\n",
    "t = Template('$name is the $title of $company')\n",
    "s = t.substitute(name='MinTic', title='Founder', company='DS4A.')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "# string capwords() function - Uses str.split() and str.capitalize()\n",
    "string.capwords('hello world ds4a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# String Methods\n",
    "# str.methods()\n",
    "\n",
    "# Changing text\n",
    "print('hello world ds4a'.capitalize())\n",
    "print('hello world ds4a'.upper())\n",
    "print('HELLO WORLD DS4A'.lower())\n",
    "print('  123456  '.lstrip())\n",
    "print('  123456  '.rstrip())\n",
    "print('  123456  '.strip())\n",
    "print('привет мир ds4a'.encode())\n",
    "print('hello world ds4a'.encode())\n",
    "print('привет мир ds4a'.encode(encoding=\"cp866\", errors=\"strict\"))\n",
    "print('hello world ds4a'.encode(encoding=\"utf-8\", errors=\"strict\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Looking in text\n",
    "print('hello world ds4a'.count('o'))\n",
    "print('hello world ds4a'.endswith('a'))\n",
    "print('hello world ds4a'.startswith('a'))\n",
    "print('hello world ds4a'.find('o'))\n",
    "print('hello world ds4a'.find('z'))\n",
    "print('hello world ds4a'.index('o'))\n",
    "print('hello world ds4a'.isalnum())\n",
    "print('123456'.isalnum())\n",
    "print('hello'.isalpha())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Regular Expressions (regex)\n",
    "\n",
    "- Versatile tool for text processing.\n",
    "- Standard library of most programming languages (Python, SQL, Javascript, etc)\n",
    "- Mini programming language\n",
    "- Parts of regular expressions can be saved for future use.\n",
    "- There are ways to perform AND, OR, NOT conditionals.\n",
    "- Operations similar to range function, string repetition operator and so on.\n",
    "\n",
    "Some common use cases:\n",
    "\n",
    "- Sanitizing a string to ensure that it satisfies a known set of rules. For example, to check if a given string matches password rules.\n",
    "- Filtering or extracting portions on an abstract level like alphabets, numbers, punctuation and so on.\n",
    "- Qualified string replacement. For example, at the start or the end of a string, only whole words, based on surrounding text, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence = 'This is a sample string'\n",
    "\n",
    "print('is' in sentence)\n",
    "print('xyz' in sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "# As a good practice, always use raw strings to construct the RE, unless other formats are required\n",
    "print(bool(re.search(r'is', sentence)))\n",
    "print(bool(re.search(r'xyz', sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if re.search(r'ring', sentence):\n",
    "    print('mission success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not re.search(r'xyz', sentence):\n",
    "    print('mission failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generator expression examples\n",
    "words = ['cat', 'attempt', 'tattle']\n",
    "\n",
    "print([w for w in words if re.search(r'tt', w)])\n",
    "\n",
    "print(all(re.search(r'at', w) for w in words))\n",
    "\n",
    "print(any(re.search(r'stat', w) for w in words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compiling regular expressions\n",
    "pet = re.compile(r'dog')\n",
    "\n",
    "print(type(pet))\n",
    "\n",
    "print(bool(pet.search('They bought a dog')))\n",
    "\n",
    "print(bool(pet.search('A cat crossed their path')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "byte_data = b'This is a sample string'\n",
    "\n",
    "# To work with bytes data type, the RE must be of bytes data as well\n",
    "try:\n",
    "    re.search(r'is', byte_data)\n",
    "except Exception as error:\n",
    "    print(\"Error in re.search: \",error)\n",
    "    print(bool(re.search(rb'is', byte_data)))\n",
    "    print(bool(re.search(rb'xyz', byte_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example applied\n",
    "filename = 'programming_quotes.txt'\n",
    "word = re.compile(r'two')\n",
    "with open(filename, 'r') as ip_file:\n",
    "   for ip_line in ip_file:\n",
    "    if word.search(ip_line):\n",
    "        print(ip_line, end='') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "purchases = '''\\\n",
    "apple 24\n",
    "mango 50\n",
    "guava 42\n",
    "onion 31\n",
    "water 10'''\n",
    "num = re.compile(r'2') \n",
    "for line in purchases.split('\\n'):\n",
    "    if not num.search(line):\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anchors\n",
    "\n",
    "- Qualifying a pattern\n",
    "- These restrictions are made possible by assigning special meaning to certain characters and escape sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# String Anchors: \n",
    "# This restriction is about qualifying a RE to match only at the start or the end of an input string.\n",
    "# The escape sequence \\A which restricts the matching to the start of string.\n",
    "\n",
    "print(bool(re.search(r'\\Acat', 'cater')))\n",
    "print(bool(re.search(r'\\Acat', 'concatenation')))\n",
    "print(bool(re.search(r'\\Ahi', 'hi hello\\ntop spot')))\n",
    "print(bool(re.search(r'\\Atop', 'hi hello\\ntop spot')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To restrict the matching to the end of string, \\Z is used.\n",
    "\n",
    "print(bool(re.search(r'are\\Z', 'spare')))\n",
    "print(bool(re.search(r'are\\Z', 'nearest')))\n",
    "\n",
    "words = ['surrender', 'unicorn', 'newer', 'door', 'empty', 'eel', 'pest']\n",
    "\n",
    "print([w for w in words if re.search(r'er\\Z', w)])\n",
    "\n",
    "print([w for w in words if re.search(r't\\Z', w)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_pat = re.compile(r'\\Acat\\Z')\n",
    "print(bool(word_pat.search('cat')))\n",
    "print(bool(word_pat.search('cater')))\n",
    "print(bool(word_pat.search('concatenation')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# insert text at the start of a string\n",
    "# first argument to re.sub is the search RE\n",
    "# second argument is the replacement value\n",
    "# third argument is the string value to be acted upon\n",
    "\n",
    "print(re.sub(r'\\A', r're', 'live'))\n",
    "print(re.sub(r'\\A', r're', 'send'))\n",
    "\n",
    "# appending text\n",
    "print(re.sub(r'\\Z', r'er', 'cat'))\n",
    "print(re.sub(r'\\Z', r'er', 'hack'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A common mistake, not specific to re.sub , is forgetting that strings are immutable in Python.\n",
    "\n",
    "word = 'cater'\n",
    "\n",
    "# this will return a string object, won't modify 'word' variable\n",
    "print(re.sub(r'\\Acat', r'hack', word))\n",
    "print(word)\n",
    "\n",
    "# need to explicitly assign the result if 'word' has to be changed\n",
    "word = re.sub(r'\\Acat', r'hack', word)\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Line anchors\n",
    "# The newline character \\n is used as the line separator\n",
    "# ˆ metacharacter for matching the start of line and $ for matching the end of line.\n",
    "# If there are no newline characters in the input string, these will behave same as \\A and \\Z respectively.\n",
    "\n",
    "pets = 'cat and dog'\n",
    "\n",
    "print(bool(re.search(r'^cat', pets)))\n",
    "print(bool(re.search(r'^dog', pets)))\n",
    "print(bool(re.search(r'dog$', pets)))\n",
    "print(bool(re.search(r'^dog$', pets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \\Z will always match the end of string, irrespective of what characters are present.\n",
    "greeting = 'hi there\\nhave a nice day\\n'\n",
    "\n",
    "print(greeting)\n",
    "\n",
    "print(bool(re.search(r'day$', greeting)))\n",
    "print(bool(re.search(r'day\\n$', greeting)))\n",
    "print(bool(re.search(r'day\\Z', greeting)))\n",
    "print(bool(re.search(r'day\\n\\Z', greeting)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Word anchors\n",
    "# The escape sequence \\b denotes a word boundary.\n",
    "\n",
    "words = 'par spar apparent spare part'\n",
    "\n",
    "print(re.sub(r'par', r'X', words))\n",
    "print(re.sub(r'\\bpar', r'X', words))\n",
    "print(re.sub(r'par\\b', r'X', words))\n",
    "print(re.sub(r'\\bpar\\b', r'X', words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = 'par spar apparent spare part'\n",
    "\n",
    "print(re.sub(r'\\b', r'\"', words).replace(' ', ','))\n",
    "print(re.sub(r'\\b', r' ', '-----hello-----'))\n",
    "print(re.sub(r'\\b', r' ', 'foo_baz=num1+35*42/num2'))\n",
    "print(re.sub(r'\\b', r' ', 'foo_baz=num1+35*42/num2').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The word boundary has an opposite anchor too. \\B matches wherever \\b doesn’t match.\n",
    "words = 'par spar apparent spare part'\n",
    "\n",
    "print(re.sub(r'\\Bpar', r'X', words))\n",
    "print(re.sub(r'\\Bpar\\b', r'X', words))\n",
    "print(re.sub(r'par\\B', r'X', words))\n",
    "print(re.sub(r'\\Bpar\\B', r'X', words))\n",
    "print(re.sub(r'\\b', r':', 'copper'))\n",
    "print(re.sub(r'\\B', r':', 'copper'))\n",
    "print(re.sub(r'\\b', r' ', '-----hello-----'))\n",
    "print(re.sub(r'\\B', r' ', '-----hello-----'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cheatsheer and Summary**\n",
    "\n",
    "![](CheatSheetandSummary1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Alternation and Grouping\n",
    "\n",
    "print(bool(re.search(r'cat|dog', 'I like cats')))\n",
    "print(bool(re.search(r'cat|dog', 'I like dogs')))\n",
    "print(bool(re.search(r'cat|dog', 'I like parrots')))\n",
    "\n",
    "\n",
    "print(re.sub(r'\\Acat|cat\\b', r'X', 'catapults concatenate cat scat'))\n",
    "print(re.sub(r'cat|dog|fox', r'mammal', 'cat dog bee parrot fox'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The join string method can be used to build the alternation list automatically from an iterable of strings.\n",
    "\n",
    "print('|'.join(['car', 'jeep']))\n",
    "\n",
    "words = ['cat', 'dog', 'fox']\n",
    "\n",
    "print('|'.join(words))\n",
    "\n",
    "print(re.sub('|'.join(words), r'mammal', 'cat dog bee parrot fox'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cheatsheer and Summary**\n",
    "\n",
    "![](CheatSheetandSummary2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from unicodedata import normalize\n",
    "\n",
    "def formatingText(text):\n",
    "\ttext = text.lower()\n",
    "\ttext = re.sub('<.*?>', '', text)\n",
    "\ttext = re.sub(':.*?:', '', text)\n",
    "\ttext = re.sub(r\"([^n\\u0300-\\u036f]|n(?!\\u0303(?![\\u0300-\\u036f])))[\\u0300-\\u036f]+\", r\"\\1\", normalize( \"NFD\", text), 0, re.I)\n",
    "\ttext = normalize( 'NFC', text)\n",
    "\ttext = re.sub('[^a-z ]', '', text)\n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(formatingText('hello@ Ds4á'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular Expressions Cheat Sheet [Here](https://cheatography.com/davechild/cheat-sheets/regular-expressions/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK\n",
    "\n",
    "Es una de las librerías más antiguas en python para procesamiento de lenguaje natural. Sigue siendo muy útil para tareas de pre procesado de texto tales como la tokenización, lematización, exclusión de palabras irrelevantes, etc. NLTK también se usa mucho como herramienta de estudio y enseñanza de procesamiento del lenguaje.  Para aprender más, puedes leer el libro de NLTK (en inglés)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('IMDB Dataset.csv',nrows=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(data.review[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def striphtml(data):\n",
    "    p = re.compile(r'<.*?>')\n",
    "    return p.sub('', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokenize(data.review[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.review = data.review.apply(striphtml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(data.review[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(data.review[1])\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(sentences[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = word_tokenize(sentences[3])\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = [w.lower() for w in words]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for w in words if not w in stop_words and w.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "textoWC = ' '.join(words)\n",
    "\n",
    "wordcloud = WordCloud(width = 600, height = 600, \n",
    "                background_color ='white', \n",
    "                stopwords = STOPWORDS,# max_words=200,\n",
    "                relative_scaling =0,\n",
    "                min_font_size = 10).generate(textoWC) \n",
    "\n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Gensim \n",
    "\n",
    "Es una librería para el procesamiento de lenguaje natural creada por Radim Řehůřek. El punto fuerte de Gensim es el modelado de temas. Es decir, puede identificar automáticamente de que tratan un conjunto de documentos. Además, Gensim es útil para construir o importar representaciones de vectores distribuidas tales como word2vec. También podemos usar Gensim para analizar la similaridad entre documentos, lo que es muy útil cuando realizamos búsquedas.  Para aprender más, mira los tutoriales de Gensim (en inglés)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "\n",
    "# How to create a dictionary from a list of sentences?\n",
    "documents = [\"The Saudis are preparing a report that will acknowledge that\", \n",
    "             \"Saudi journalist Jamal Khashoggi's death was the result of an\", \n",
    "             \"interrogation that went wrong, one that was intended to lead\", \n",
    "             \"to his abduction from Turkey, according to two sources.\"]\n",
    "\n",
    "# Tokenize(split) the sentences into words\n",
    "texts = [[text for text in doc.split()] for doc in documents]\n",
    "\n",
    "# Create dictionary\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "# Get information about the dictionary\n",
    "print(dictionary.token2id)\n",
    "#> Dictionary(33 unique tokens: ['Saudis', 'The', 'a', 'acknowledge', 'are']...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy \n",
    "\n",
    "Es la librería de procesamiento natural más rápida que existe. Está diseñada para usarse en aplicaciones reales y extraer información relevante. spaCy también es muy útil para preparar texto para otras tareas de aprendizaje automático. Por ejemplo, podemos preparar los datos para usarlos con TensorFlow, PyTorch, scikit-learn, Gensim, etc. Con spaCy también vamos a poder construir modelos lingüísticos estadísticos sofisticados para muchos de los problemas de procesamiento de lenguaje natural.  Para saber más, mira la documentación de spaCy (en inglés).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_name = 'programming_quotes.txt'\n",
    "introduction_file_text = open(file_name).read()\n",
    "introduction_file_doc = nlp(introduction_file_text)\n",
    "\n",
    "# Extract tokens for the given doc\n",
    "print ([token.text for token in introduction_file_doc])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('case_1.1_var2': conda)",
   "language": "python",
   "name": "python37664bitcase11var2condaa1506117ab73487ba6cee4d98af19099"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
