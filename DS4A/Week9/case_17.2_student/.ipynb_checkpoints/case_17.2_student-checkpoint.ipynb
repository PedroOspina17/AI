{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How can we predict the sentiment associated with a customer interaction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pylab import rcParams\n",
    "from wordcloud import WordCloud\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "rcParams['figure.figsize'] = 30, 60\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "\n",
    "After working through this case, you should be able to apply sentiment analysis to business problems. You will understand how to use text classification techniques to build a sentiment analysis model, and you'll be able to apply sentiment models to real-world data.\n",
    "\n",
    "You will have gained experience using a number of different vectorization and model-building techniques, using popular Python libraries such as [scikit-learn](https://scikit-learn.org/stable/) and [gensim](https://github.com/RaRe-Technologies/gensim). You'll have used both count-based vectorizations and word embeddings, and you'll understand the pros and cons of each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "**Business Context.** You are a data scientist for a large e-commerce firm. You have tens of thousands of customers writing reviews on products each day. Each review contains textual feedback along with a 1-to-5 star rating system (1 being least satisfied and 5 being most satisfied). You also have a customer support team which interacts with customers over call and messaging services. Your company also collects feedback about your customers' experiences with the website interaction after each purchase. Neither this feedback nor the messaging service have a rating number. The firm wants to quantify customer satisfaction coming from these non-rated interactions in order to help with further business decisions (e.g. determine how well your various customer service agents are doing).\n",
    "\n",
    "**Business Problem.** Your task is to **build models which can identify the sentiment (positive or negative) of each of these non-rated interactions**.\n",
    "\n",
    "**Analytical Context.** The data is a set of reviews in CSV file format. We will combine what we learned about text processing and classification models to develop algorithms capable of classifying interactions by sentiment.\n",
    "\n",
    "The case is structured as follows: you will 1) read and analyze the input text data and the corresponding response variables (ratings); 2) perform basic pre-processing to prepare the data for modeling; 3) learn and apply various ways of featurizing the reviews text; and finally 4) build machine learning models to classify text as either exhibiting positive or negative sentiment (1 or 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and performing basic analysis of the data\n",
    "\n",
    "As usual the first step is to read the available data and perform some high-level analysis on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_reviews = pd.read_csv('Reviews.csv')\n",
    "\n",
    "# Selecting just 10,000 records for faster computation. \n",
    "# Feel free to comment the following line of code later, to build ML models using all the data.\n",
    "\n",
    "amazon_reviews = amazon_reviews[:10000]\n",
    "amazon_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset contains the following columns:\n",
    "\n",
    "* **ID**: A unique ID for each row in the dataset\n",
    "* **ProductId**: A reference to the product that the review is about\n",
    "* **UserId**: A reference to the user who left the review\n",
    "* **HelpfulnessNumerator**: The number of readers of the review who indicated that it was \"helpful\"\n",
    "* **HelpfulnessDenominator**: The total number of people who gave an indication of whether or not the review was \"helpful\"\n",
    "* **Score**: The star rating (1-5)\n",
    "* **Time**: A Unix timestamp indicating when the review was created\n",
    "* **Summary**: The user-written summary of what the review is about\n",
    "* **Text**: The user-written review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the distribution of number of words per review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x25589610788>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Getting the number of words by splitting them by a space\n",
    "words_per_review = amazon_reviews.Text.apply(lambda x: len(x.split(\" \")))\n",
    "words_per_review.hist(bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.9028"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_per_review.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also look at the distribution of ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    6183\n",
       "4    1433\n",
       "1     932\n",
       "3     862\n",
       "2     590\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_reviews.Score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    61.83\n",
       "4    14.33\n",
       "1     9.32\n",
       "3     8.62\n",
       "2     5.90\n",
       "Name: Score, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_val = 100 * amazon_reviews.Score.value_counts()/amazon_reviews.shape[0]\n",
    "percent_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x25589a23048>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "percent_val.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution is quite skewed, with a giant number of 5s and very few 3s, 2s, and 1s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1:\n",
    "\n",
    "Create a word cloud for the product reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "WordCloud has not been calculated, call generate first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4a1d49ecea2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\DS4A\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2682\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2683\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[1;32m-> 2684\u001b[1;33m         None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2685\u001b[0m     \u001b[0msci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2686\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\DS4A\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1597\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\DS4A\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    367\u001b[0m                 \u001b[1;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\DS4A\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    367\u001b[0m                 \u001b[1;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\DS4A\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5677\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5679\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5680\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5681\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\DS4A\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m                 \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpil_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Needed e.g. to apply png palette.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msafe_masked_invalid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m         if (self._A.dtype != np.uint8 and\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\DS4A\\lib\\site-packages\\matplotlib\\cbook\\__init__.py\u001b[0m in \u001b[0;36msafe_masked_invalid\u001b[1;34m(x, copy)\u001b[0m\n\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msafe_masked_invalid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    796\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnative\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m         \u001b[1;31m# Note that the argument to `byteswap` is 'inplace',\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\DS4A\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    737\u001b[0m             \u001b[0mWord\u001b[0m \u001b[0mcloud\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \"\"\"\n\u001b[1;32m--> 739\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    740\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\DS4A\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mto_array\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    727\u001b[0m             \u001b[0mWord\u001b[0m \u001b[0mcloud\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m         \"\"\"\n\u001b[1;32m--> 729\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\DS4A\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mto_image\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_generated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    641\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m             \u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\DS4A\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36m_check_generated\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[1;34m\"\"\"Check if ``layout_`` was computed, otherwise raise error.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"layout_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m             raise ValueError(\"WordCloud has not been calculated, call generate\"\n\u001b[0m\u001b[0;32m    637\u001b[0m                              \" first.\")\n\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: WordCloud has not been calculated, call generate first."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wc = WordCloud(amazon_reviews[\"Text\"])\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(wc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word cloud indicates that many of the reviews talk about food-related things - coffee, flavor, food, taste, drink. We also see some positive words like good, love, best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing the ratings for sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of sentiment analysis, we will convert all of the ratings into binary values using the follow rule: ratings of 4 or 5 will get mapped to 1 (indicating \"positive\"), ratings of 1 or 2 will get mapped to 0 (indicating \"negative\"), and ratings of 3 will get removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_reviews['Sentiment_rating'] = np.where(amazon_reviews.Score > 3, 1, 0)\n",
    "amazon_reviews['Sentiment_rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing neutral reviews \n",
    "amazon_reviews = amazon_reviews[amazon_reviews.Score != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 5, 3\n",
    "amazon_reviews.Sentiment_rating.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed previously, text preprocessing and normalization is crucial before building a proper NLP model. Some of the important steps are:\n",
    "\n",
    "1. converting words to lower/upper case\n",
    "2. removing special characters\n",
    "3. removing stopwords and high/low-frequency words\n",
    "4. stemming/lemmatization\n",
    "\n",
    "You should know most of these already, although number 4 is new. Let's proceed in order. Let's start by converting all of the words into a consistent case format, say lowercase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_reviews['reviews_text_new'] = amazon_reviews.Text.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "token_lists = [word_tokenize(each) for each in amazon_reviews.Text]\n",
    "tokens = [item for sublist in token_lists for item in sublist]\n",
    "print(\"Number of unique tokens then: \", len(set(tokens)))\n",
    "\n",
    "token_lists_lower = [word_tokenize(each) for each in amazon_reviews.reviews_text_new]\n",
    "tokens_lower = [item for sublist in token_lists_lower for item in sublist]\n",
    "print(\"Number of unique tokens now: \", len(set(tokens_lower)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of tokens has gone down by ~18% just from normalizing the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2:\n",
    "\n",
    "Is removing special characters even a good idea? What are some examples of characters that would likely be safe to remove, and what are some that would not be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of simplicity, we will proceed by removing all of the special characters; however, it pays to keep in mind that this is something to revisit depending on the results we get later. The following gives a list of all the special characters in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting non alpha numeric charactes that are not spaces\n",
    "special_chars = amazon_reviews.reviews_text_new.apply(lambda x: [each for each in list(x) if not each.isalnum() and each != ' '])\n",
    "\n",
    "# Getting list of list into a single list\n",
    "flat_list = [item for sublist in special_chars for item in sublist]\n",
    "\n",
    "# Unique special characters\n",
    "print(set(flat_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove these special characters from the reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "review_backup = amazon_reviews.reviews_text_new.copy()\n",
    "amazon_reviews.reviews_text_new = amazon_reviews.reviews_text_new.apply(\n",
    "    lambda x: re.sub('[^A-Za-z0-9 ]+', ' ', x)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how our reviews change after removing these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Old Review:\")\n",
    "review_backup.values[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"New Review:\")\n",
    "amazon_reviews.reviews_text_new[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of unique tokens has dropped further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_lists = [word_tokenize(each) for each in amazon_reviews.Text]\n",
    "tokens = [item for sublist in token_lists for item in sublist]\n",
    "print(\"Number of unique tokens then: \", len(set(tokens)))\n",
    "\n",
    "token_lists = [word_tokenize(each) for each in amazon_reviews.reviews_text_new]\n",
    "tokens = [item for sublist in token_lists for item in sublist]\n",
    "print(\"Number of unique tokens now: \", len(set(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords and high/low frequency words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed before, stopwords naturally occur very frequently in the English language without adding any context specific insights. It makes sense to remove them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "noise_words = []\n",
    "stopwords_corpus = nltk.corpus.stopwords\n",
    "eng_stop_words = stopwords_corpus.words('english')\n",
    "noise_words.extend(eng_stop_words)\n",
    "print(len(noise_words))\n",
    "noise_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3:\n",
    "\n",
    "Find the high- and low-frequency words, which we will define as the 1% of words that occur most often in the reviews, as well as define the 1% of words that occur least often in the reviews (after adjusting for case and special characters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_words.extend([word for word,val in top_1_percentile])\n",
    "noise_words.extend([word for word,val in bottom_1_percentile])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop words and high/low frequency words have now been added to `noise_words`, which will be removed from the reviews prior to training machine learning models. The common words are unlikely to be that useful as we expect them to appear about as often in positive and negative reviews. The uncommon words might be more meaningful and could in theory indicate the sentiment of the review, but as they appear so seldom our model would not be able to learn any meaning from them.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming & lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready for the last part of our pre-processing - **[stemming & lemmatization](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html)**.\n",
    "\n",
    "Different forms of a word often communicate essentially the same meaning. For example, theres probably no difference in intent between a search for `shoe` and a search for `shoes`. The same word may also appear in different tenses; e.g. \"run\", \"ran\", and \"running\". These syntactic differences between word forms are called **inflections**. In general, we probably want to treat inflections identically when featurizing our text.\n",
    "\n",
    "Sometimes this process is nearly-reversible and quite safe (e.g. replacing verbs with their infinitive, so that \"run\", \"runs\", and \"running\" all become \"run\"). Other times it is a bit dangerous and context-dependant (e.g. replacing superlatives with their base form, so that \"good\", \"better\", and \"best\" all become \"good\"). The more aggressive you are, the greater the potential rewards and risks. For a very aggressive example, you might choose to replace \"Zeus\" and \"Jupiter\" with \"Zeus\" only; this might be OK if you are summarizing myths, confusing if you are working on astronomy, and disastrous if you are working on comparative mythology.\n",
    "\n",
    "We won't get into the details of the differences between [stemming](http://www.nltk.org/api/nltk.stem.html?highlight=lemmatizer), [lemmatization](http://www.nltk.org/api/nltk.stem.html?highlight=lemmatizer#module-nltk.stem.wordnet) and other types of text normalization here, but a careful introduction can be found at: https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer, LancasterStemmer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming algorithms** work by cutting off the end or the beginning of the word, taking into account a list of common prefixes and suffixes that can be found.\n",
    "\n",
    "On the other hand, **lemmatization** takes into consideration the morphological analysis of the words. So lemmatization takes into account the grammar of the word and tries to find the root word instead of just getting to the root word by brute force methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lancaster Stemmer\")\n",
    "print(lancaster.stem(\"trouble\"))\n",
    "print(lancaster.stem(\"troubling\"))\n",
    "print(lancaster.stem(\"troubled\"))\n",
    "\n",
    "# Provide a word to be lemmatized\n",
    "print(\"WordNet Lemmatizer\")\n",
    "print(lemmatizer.lemmatize(\"trouble\", wordnet.NOUN))\n",
    "print(lemmatizer.lemmatize(\"troubling\", wordnet.VERB))\n",
    "print(lemmatizer.lemmatize(\"troubled\", wordnet.VERB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that we get a meaning root word from Lemmatizer while Stemmer just cuts out and extracts the first important part of the word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have cleaned-up versions of two very important pieces of data  the actual review text and its corresponding sentiment rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_reviews[['Text','Score','Sentiment_rating']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The independent variables or model features are derived from the review text. Previously, we discussed how we can use n-grams to create features, and specifically how bag-of-words is the simplest interpretation of these n-grams, disregarding order and context entirely and only focusing on frequency/count. Let's use that as a starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CountVectorizer` is a Python class that automatically accounts for certain preprocessing steps like removing stopwords, stemming, creating n-grams, and word tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a method for stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this to create a bag of words from the reviews, excluding the noise words we identified earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a python object of the class CountVectorizer\n",
    "\n",
    "bow_counts = CountVectorizer(\n",
    "    tokenizer=word_tokenize,\n",
    "    stop_words=noise_words,\n",
    "    ngram_range=(1, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the bag of words is prepared, the dataset should be divided into training and test sets. We could also split the data after vectorizing it, but it's useful to split the data as early as possible in the process. This means that once we have generated our predictions, we can more easily compare them with the original texts, before they have been preprocessed and vectorized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train, reviews_test = train_test_split(amazon_reviews, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bow = bow_counts.fit_transform(reviews_train.reviews_text_new)\n",
    "X_test_bow = bow_counts.transform(reviews_test.reviews_text_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we call `fit_transform` to vectorize our training set and `transform` to vectorize our test set. This builds the vectorization mappings *only* on data from the training set, which is a restriction we would be faced with in a real-world problem (not having access to testing data during training time).\n",
    "\n",
    "Therefore, there may be some words in the test set which we don't know how to vectorize and they will be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bow = reviews_train['Sentiment_rating']\n",
    "y_test_bow = reviews_test['Sentiment_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_bow.value_counts() / y_test_bow.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test data contains 84% positive sentiment reviews. The simplest prediction model we could think of would be one that predicts \"positive\" for every input. We would call this a \"naive\" model, and it makes for a useful baseline. In this case, such a model would get 84% accuracy, so we can consider this a baseline score that our machine learning model needs to beat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model on our training data and run the resulting model on our test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model \n",
    "lr_model_all = LogisticRegression(C=1, solver=\"liblinear\")\n",
    "lr_model_all.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "# Predicting the output\n",
    "test_pred_lr_prob = lr_model_all.predict_proba(X_test_bow)\n",
    "test_pred_lr_all = lr_model_all.predict(X_test_bow)\n",
    "\n",
    "print(\"F1 score: \", f1_score(y_test_bow, test_pred_lr_all))\n",
    "print(\"Accuracy: \", accuracy_score(y_test_bow, test_pred_lr_all) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = [each[1] for each in test_pred_lr_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame()\n",
    "predictions['Text'] = reviews_test['Text']\n",
    "predictions['Actual_Score'] = reviews_test['Score']\n",
    "predictions['Sentiment_rating'] = reviews_test['Sentiment_rating']\n",
    "predictions['Predicted_sentiment'] = test_pred_lr_all\n",
    "predictions['Predicted_probability'] = probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(predictions['Sentiment_rating'], predictions['Predicted_sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4:\n",
    "\n",
    "In the `Predicted_probability` column you can see how confident the model was in its predictions, with probabilities very close to 0 being very confident negative sentiment predictions, and probabilities very close to 1 being very confident positive sentiment predictions.\n",
    "\n",
    "Use this information to find the case where the model was *most confident* in predicting a review as having a negative sentiment when the actual score was positive.\n",
    "\n",
    "Look at the review text and write a few sentences of analysis about why you think the model got it wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5:\n",
    "\n",
    "Modify the set of features in the model to include bigrams, trigrams, and 4-grams. Don't remove the noise words defined earlier before featurizing. (Hint: set `ngram_range=(1,4)`.) \n",
    "\n",
    "At the same time, experiment with hyperparameter tuning. Change the `C` value of the logistic regression classifier to 0.9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6:\n",
    "\n",
    "Perform random forests classification on our feature set just as we did above with logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not quite as good as logistic regression. We can get the n-grams which were most important for the predictions as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(\n",
    "    rf_model_all.feature_importances_,\n",
    "    index=bow_counts.get_feature_names(),\n",
    "    columns=['importance']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances.sort_values(['importance'], ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, bag-of-words are not the only way to featurize text. Another method, which we briefly touched upon before, is the **Term Frequency-Inverse Document Frequency (TF-IDF)** method. This evaluates how important a word is to a document within a large collection of documents (i.e. corpus). The importance increases proportionally based on the number of times a word appears in the document but is offset by the frequency of the word in the corpus.\n",
    "\n",
    "The TF-IDF weight is the product of two terms. The first computes the normalized Term Frequency (TF); i.e. the number of times a word appears in a document divided by the total number of words in that document. The second term is the Inverse Document Frequency (IDF), computed as the logarithm of the number of the documents in the corpus divided by the number of documents where the specific term appears:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='tf-idf.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Less formally, what does this mean?\n",
    "\n",
    "* If a word appears very often in a specific document, it is likely to be significant.\n",
    "* If a word appears very often throughout nearly all documents in the corpus, it is unlikely to be significant.\n",
    "* Therefore, a word that appears often in one document but *rarely* in the rest of the corpus deserves special attention.\n",
    "\n",
    "TF-IDF doesn't just count each word - it applies a weighting so that common words receive less attention and rare words receive more.\n",
    "\n",
    "Let's re-featurize our original set of reviews based on TF-IDF and split the resulting features into train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vectorizer - we still feed in our stop words, although\n",
    "# these are less relevant now as TF-IDF would weight them less \n",
    "# anyway.\n",
    "tfidf_counts = TfidfVectorizer(\n",
    "    tokenizer=word_tokenize,\n",
    "    stop_words=noise_words,\n",
    "    ngram_range=(1,1)\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf_counts.fit_transform(reviews_train.reviews_text_new)\n",
    "X_test_tfidf = tfidf_counts.transform(reviews_test.reviews_text_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying logistic regression to TF-IDF features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply logistic regression to the features created from TF-IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the classifier\n",
    "lr_model_tf_idf = LogisticRegression(solver=\"liblinear\")\n",
    "\n",
    "# Train the classifier\n",
    "lr_model_tf_idf.fit(X_train_tfidf, y_train_bow)\n",
    "\n",
    "# Predict the results\n",
    "test_pred_lr_prob = lr_model_tf_idf.predict_proba(X_test_tfidf)\n",
    "test_pred_lr_all = lr_model_tf_idf.predict(X_test_tfidf)\n",
    "\n",
    "## Evaluating the model\n",
    "print(\"F1 score: \",f1_score(y_test_bow, test_pred_lr_all))\n",
    "print(\"Accuracy: \", accuracy_score(y_test_bow, test_pred_lr_all) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have attained an accuracy of 88% with TF-IDF as compared to 90% with 1-grams. It's hard to know exactly why this more sophisticated vectorizing algorithm leads to worse results, but it could be that penalising words that are common across the corpus leads to a disadvantage for this particular dataset. TF-IDF is often useful when the testing data is very different from the training data, allowing words that are only common in the training set to be deprioritized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7:\n",
    "\n",
    "Try increasing the accuracy of the model by \n",
    "\n",
    "* setting `ngram_range=(1,4)` in the Vectorizer\n",
    "* not removing the noise words beforehand in the Vectorizer\n",
    "* setting `C=10` in the LogisticRegression classsifier\n",
    "* setting `penalty=\"l1\"` in the LogisticRegression classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an improvement on our previous result, but we made four changes at the same time, so we don't know which ones helped and how much.\n",
    "    \n",
    "Trying different hyperparameters to improve your model is called **hyperparameter tuning** and is a huge field on its own. You can imagine how running this model 16 times, once with each possible configuration of hyperparamters we have tried, would already get kind of tricky to keep track, and this is only with 4 hyperparameters and two values for each! With 100s or 1000s of hyperparameters and 100s or 1000s of values for each, the total combinations grows very quickly.\n",
    "\n",
    "To help with this, scikit-learn provides so-called \"[grid search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\" functionality, where you can set up a pipeline and specify the ranges of hyperparmeters you want to \"search\". scikit-learn will try each combination and train and evaluate the model for each case, telling you which one performed the best.\n",
    "\n",
    "We can also find our most important features again, as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_weights = pd.DataFrame(\n",
    "    list(\n",
    "        zip(tfidf_counts.get_feature_names(), lr_model_tf_idf_new.coef_[0])\n",
    "    ),\n",
    "    columns=['words','weights']\n",
    ")\n",
    "\n",
    "lr_weights.sort_values(['weights'],ascending = False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_weights.sort_values(['weights'],ascending = False)[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final type of featurization we will cover are **word embeddings**. This is a type of word representation that allows words with similar meaning to have a similar representation. By being pre-trained on external data, such as Wikipedia, word embeddings know when concepts are *semantically* related -- for example the vectors for \"king\" and \"queen\" would be located near each other, even though there is no syntactic or spelling similarity between these words.\n",
    "\n",
    "It is this approach to representing words and documents that may be considered one of the key breakthroughs of deep learning on challenging natural language processing problems.\n",
    "    \n",
    "There are many datasets of pre-trained word embeddings that are freely available, or you can train your own. Some major breakthroughs in this area include [Word2Vec](https://en.wikipedia.org/wiki/Word2vec), which became a poster child of NLP, and other embeddings approaches such as [Glove](https://nlp.stanford.edu/projects/glove/), [ELMo](https://allennlp.org/elmo) and [BERT](https://github.com/google-research/bert)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following image, each of the words have been represented in 2-dimensions for simplicity. In reality, embeddings are usually represented in at least 50 dimensions (often far more, actually). It can be clearly seen that words with similar context are grouped together  bathroom, kitchen, bathtub are grouped together, while microwave, refrigerator, oven form another group, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='wembeddings.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different methods to learn word embeddings - Word2Vec, GloVe, FastText. **Word2Vec** uses a shallow Neural Network and is of two types; _CBOW_ and _Skip Gram_. **GloVe** is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space. **[fastText](https://fasttext.cc/)** is a library for learning of word embeddings and text classification created by Facebook's AI Research lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why use word embeddings over bag-of-words and TF-IDF?\n",
    "\n",
    "Each word is represented by a real-valued vector, which generally has tens or hundreds of dimensions. This is in contrast to he thousands or millions of dimensions required for sparse word representations. Thus, word embeddings can drastically reduce the number of dimensions required for representing a text document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a pre-trained glove word embedding that is trained on a Twitter dataset \n",
    "# This word embedding is 200 dimensional, meaning that each word is represented\n",
    "# by a 200 dimensional vector.\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "    os.path.join(os.getcwd(), 'glove.twitter.27B.200d_out.txt'),\n",
    "    binary=False,\n",
    "    unicode_errors='ignore'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had approximately 18,000 distinct tokens for 1-gram features in the bag-of-words representation, yet will only have 200 dimensions in this word embedding. This is a huge difference!\n",
    "\n",
    "Moreover, word embeddings capture the context and semantics of the sentences since each word vector representation is itself based on its contextual meaning.\n",
    "\n",
    "Below is the vector representation for \"food\" and \"great\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The embedding for food is\", len(model['food']), \"dimensional\")\n",
    "\n",
    "model['food']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The embedding for great is\", len(model['great']), \"dimensional\")\n",
    "\n",
    "model['great']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we discussed, the power of word embeddings is that that words that have a similar meaning are closer together in vector space. We can demonstrate this by looking at the cosine distance between some pairs of words as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_similarity(word1, word2, model):\n",
    "    v1 = model[word1]\n",
    "    v2 = model[word2]\n",
    "    similarity = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "    print(f\"{word1} and {word2} are {round(similarity * 100)}% similar\")\n",
    "\n",
    "print_similarity(\"cat\", \"dog\", model)\n",
    "print_similarity(\"good\", \"bad\", model)\n",
    "print_similarity(\"great\", \"good\", model)\n",
    "print_similarity(\"grass\", \"model\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, \"similar meaning\" is loosely defined as \"used in similar contexts\". Because there are many examples such as \"I stroked my cat\" and \"I stroked my dog\" where these words are used in similar contexts, they are regarded as very similar. There are also many sentences where \"good\" and \"bad\" can be interchanged and the sentence can remain valid, so although we regard these as \"opposite\" our model will regard them as similar. \"grass\" and \"model\" have nearly nothing to do with each other, so they are very far apart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the vector for an entire review, we get the vector for each word in the review separately and take a simple average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8:\n",
    "\n",
    "Calculate the vector for every single review in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading your own word vectors is great to understand how they work, but higher-level libraries that abstract away code like that shown above also exist. In industry, a widely used NLP library is [SpaCy](https://spacy.io/). This library allows you efficiently extract the word embeddings from texts and carry out high-level operations on them.\n",
    "\n",
    "Let's convert the list of vector representations for each review into a DataFrame and split it into train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_data = pd.DataFrame(review_embeddings)\n",
    "embedding_data = embedding_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_embed, X_test_embed, y_train_embed, y_test_embed =  train_test_split(\n",
    "    embedding_data,\n",
    "    amazon_reviews.Sentiment_rating,\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now apply logistic regression to our word embeddings representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(penalty=\"l1\", C=10, solver=\"liblinear\")\n",
    "lr_model.fit(X_train_embed, y_train_embed)\n",
    "test_pred_lr_prob = lr_model.predict_proba(X_test_embed)\n",
    "test_pred_lr_all = lr_model.predict(X_test_embed)\n",
    "\n",
    "print(\"F1 score: \", f1_score(y_test_embed, test_pred_lr_all))\n",
    "print(\"Accuracy: \", accuracy_score(y_test_embed, test_pred_lr_all)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, this is not as good as either the bag-of-words or TF-IDF representations. Furthermore, although word embeddings was really effective at reducing the overall number of dimensions, it suffers from the problem of interpretability. This means that it is very hard for us to even diagnose what is causing its sub-par performance.\n",
    "\n",
    "However remember how \"good\" and \"bad\" were close together in vector space? This is one reason why word embeddings may not perform as well for sentiment analysis in smaller datasets - word embeddings are good at using \"knowledge\" from the external world (latent in the pre-trained embeddings) to inferr additional information about a smaller dataset, but in the case of sentiment analysis this might do more harm than good by conflating \"similar\" words that are actually very separate for a sentiment analysis task.\n",
    "\n",
    "In our case, creating features using TF-IDF got us an accuracy of 92% with very interpretable features. This is a good combination and so we deem this the best model for us here.\n",
    "\n",
    "Note that for a real experiment, we would have split our dataset into *three* parts, not just two. When running an experiment multiple times with different parameters, it's almost certain that some results will be better simply by chance, and it's bad science to select the best performing model after dozens or hundreds of runs.\n",
    "    \n",
    "To avoid this problem, the data should be split into \"training\", \"test\", and \"validation\" sets. The \"test\" set should be set aside at the start of the experiment and never looked at. The model should be tuned by using the \"validation\" set.\n",
    "\n",
    "Only once the experimenter is happy with the model by improving the performance on the validation set should the model be run on the test set, and those final results taken as the final results of the experiment. \n",
    "\n",
    "You can read more details about this methodology [here](https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we cleaned up and featurized an Amazon reviews dataset and built some classification models on these featurizations to predict sentiment. We saw that bag-of-words and TF-IDF both gave interpretable features, while word embeddings did not really. Through increasing the set of n-grams we used from 1-grams to up to 4-grams, we were able to get our logistic regression model accuracy up to 92%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building machine learning models on text is a very involved discipline. Some important things of note are as follows:\n",
    "\n",
    "1. Although there are different types of pre-processing involved in textual data, not everything has to be applied in each case. For instance, when dealing with text messages, special characters might represent important information and need not be removed. Furthermore, upper case may mean someone is angry and represents shouting, so uppercase and lowercase may represent valuable information. In other situations, it's more valuable to normalize these.\n",
    "\n",
    "2. Hyperparameter tuning in machine learning models is a very important step and while default hyperparameters work well in many cases, extra performance can often be gained through tuning these. Different sets of parameters have to be tried to see what contributes to the best model.\n",
    "\n",
    "3. Every NLP classification task is different, but the process to be followed is similar to what we did in this case: wrangle the data -> create features from text -> train models -> evaluate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
