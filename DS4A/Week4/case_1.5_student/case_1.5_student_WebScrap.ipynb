{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Automating the Extraction of Financial Data for Stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "\n",
    "Data collection is a huge part of being a data professional. Very often, we develop real-time analytics that needs to be pulling data continuously from different sources, or we need additional data to enrich our analyses. In some cases, this data is publicly available on the Internet, but it may be scattered across various websites that are updated continuously. Extracting this data manually is a very tedious task.\n",
    "\n",
    "The action of extracting data from websites is commonly known as **web scraping**. The main goal of this case is to learn the basics of web scraping using Python and the `BeautifulSoup` library. By the end of this case, you will have learned some basics of Hypertext Markup Language (HTML) jargon and the most important methods of `BeautifulSoup`, which will help you get started with web scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Business Context.** You have recently joined the data science division of a multinational bank. Over the past month you've been working with a variety of stock data and are looking to gather fundamental data on a select group of energy stocks. Your firm is specifically interested in making investments in one of the following five energy sector companies:\n",
    "\n",
    "1. Dominion Energy Inc. (Stock Symbol: D)\n",
    "2. Exelon Corp. (Stock Symbol: EXC)\n",
    "3. NextEra Energy Inc. (Stock Symbol: NEE)\n",
    "4. Southern Co. (Stock Symbol: SO)\n",
    "5. Duke Energy Corp. (Stock Symbol: DUK)\n",
    "\n",
    "Your firm wants you to gather information about each stock's earnings-per-share (EPS), price-to-earnings ratio (PE ratio), and market capitalization data in order to make their investment decision. However, the firm has no experience doing this in an automated fashion, instead relying on time-consuming manual labor up to this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Business Problem.** Your boss has posed the following question to you: **\"How can we automate the gathering of earnings-per-share (EPS), price-to-earnings ratio (PE ratio), and market capitalization data?\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analytical Context.**  In this case, you will learn the key skill of **web scraping** â€“ the practice of automatically grabbing information off of online webpages, then parsing and transforming that information into a format amenable to further analysis.\n",
    "\n",
    "In this case, you will: (1) learn the basics of HTML, which governs almost all static webpages; (2) parse a sample HTML document; (3) extract the necessary info from a single stock's HTML document; (4) scale this process to all symbols; and (5) learn how to scrape the contents of an HTML document from a live webpage in real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries needed for basic web-scraping\n",
    "from IPython.core.display import HTML\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import IFrame\n",
    "import urllib # package required to interact with live webpage\n",
    "import pandas as pd # will use to store the data from the webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of Hyper Text Markup Language (HTML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to automate the scraping and processing of stock data, you must become familiar with Hyper Text Markup Language (HTML). HTML is a markup language for creating web pages and applications; you interact with HTML constantly while you are browsing the web as the vast majority of pages are written using HTML. Some important points to keep in mind as we go over the basics of HTML:\n",
    "\n",
    "1. HTML is traditionally used to design static (i.e. non-interactive) web pages\n",
    "2. HTML uses a nested data structure with tags to instruct browsers how to display content\n",
    "3. HTML is platform independent\n",
    "4. HTML can be integrated into other languages (e.g. JavaScript)\n",
    "5. HTML can be created using any text editor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An HTML document is made up of a series of tags. These tags instruct a browser on how to display content to the user. Different tags will cause different output styles to be displayed.\n",
    "\n",
    "Let's begin by discussing a simple HTML formatted string, ```custom_html_doc```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_html_doc = \"\"\"\n",
    "<html>\n",
    "<head>\n",
    "<title>HTML Page Title</title>\n",
    "</head>\n",
    "<h1>Head: Important Header: Global News</h1>\n",
    "<br>\n",
    "<h2>Head: Less Imporant Header: Global News</h2>\n",
    "<body>\n",
    "<p class=\"title\"><b>Paragraph: Financial news</b></p>\n",
    "<p class=\"story\"> Stocks had a volatile week, where\n",
    "<a href=\"https://finance.yahoo.com/quote/duk/\" target=\"_blank\" class=\"stock\" id=\"link1\">DUK</a>,\n",
    "<a href=\"https://finance.yahoo.com/quote/d/\" target=\"_blank\" class=\"stock\" id=\"link2\">D</a>,\n",
    "<a href=\"https://finance.yahoo.com/quote/exc/\" target=\"_blank\" class=\"stock\" id=\"link3\">EXC</a>,\n",
    "<a href=\"https://finance.yahoo.com/quote/nee/\" target=\"_blank\" class=\"etf\" id=\"link4\">NEE</a>,\n",
    "<a href=\"https://finance.yahoo.com/quote/so/\" target=\"_blank\" class=\"stock\" id=\"link5\">SO</a>,\n",
    "were all making headlines.</p>\n",
    "<p class=\"details\">End of HTML document.</p>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there are a wealth of tags available in HTML, the above example highlights the fundamentals we need to get started with the language. The four vital tags of any HTML document inlcude:\n",
    "\n",
    "1. < html > Instructs the browser that your web page is in HTML format.\n",
    "2. < head > This is information that can be used by external sources (such as search engines). Holds webpage metadata.\n",
    "3. < title > Viewers see the title in the browser toolbar, when the page is added to favorites, and in search engine results.\n",
    "4. < body > Defines the body block, which contains the content of the page, including text and images.\n",
    "\n",
    "Other structurally useful tags include:\n",
    "\n",
    "1. < p > Defines a paragraph block which primarily contains text to be displayed to the user\n",
    "2. < a > Defines a hyperlink\n",
    "3. < h1 > Defines an important header\n",
    "4. < h2 > Define a less important header\n",
    "5. < br > Define a line break\n",
    "\n",
    "We can view how ```custom_html_doc``` will render using the method ```HTML()```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<html>\n",
       "<head>\n",
       "<title>HTML Page Title</title>\n",
       "</head>\n",
       "<h1>Head: Important Header: Global News</h1>\n",
       "<br>\n",
       "<h2>Head: Less Imporant Header: Global News</h2>\n",
       "<body>\n",
       "<p class=\"title\"><b>Paragraph: Financial news</b></p>\n",
       "<p class=\"story\"> Stocks had a volatile week, where\n",
       "<a href=\"https://finance.yahoo.com/quote/duk/\" target=\"_blank\" class=\"stock\" id=\"link1\">DUK</a>,\n",
       "<a href=\"https://finance.yahoo.com/quote/d/\" target=\"_blank\" class=\"stock\" id=\"link2\">D</a>,\n",
       "<a href=\"https://finance.yahoo.com/quote/exc/\" target=\"_blank\" class=\"stock\" id=\"link3\">EXC</a>,\n",
       "<a href=\"https://finance.yahoo.com/quote/nee/\" target=\"_blank\" class=\"etf\" id=\"link4\">NEE</a>,\n",
       "<a href=\"https://finance.yahoo.com/quote/so/\" target=\"_blank\" class=\"stock\" id=\"link5\">SO</a>,\n",
       "were all making headlines.</p>\n",
       "<p class=\"details\">End of HTML document.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the HTML as it would appear by a web browser\n",
    "HTML(custom_html_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the most important header < h1 > tag is responsible for the largest bold text in the document. Moreover, the paragraph tags cause the text nested in between their tags to be displayed in a regular-sized, non-bolded font. The hyperlink tags introduce the website links for each stock symbol (DUK, D, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1:\n",
    "\n",
    "Do all tags in an HTML document require an end tag?\n",
    "\n",
    "(a) Yes, all tags must be terminated for the browser to properly display the webpage\n",
    "\n",
    "(b) No, there are some tags in HTML that do not require an end tag\n",
    "\n",
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2:\n",
    "\n",
    "The following HTML document was found with all of its end tags missing. Starting from top to bottom, determine the correct order in which end tags should be added to eliminate the issues with the document.\n",
    "\n",
    "```\n",
    "<h1>This is a Heading\n",
    "<p>This is a paragraph.\n",
    "<br>\n",
    "<p>Another paragraph\n",
    "<br>\n",
    "```\n",
    "\n",
    "(a) < /h1 >, < /p >, < /br >, < /p >\n",
    "\n",
    "(b) < /h1 >, < /p >,  < /br >, < /p >, < /br >\n",
    "\n",
    "(c) < /h1 >, < /p >, < /p >\n",
    "\n",
    "(d) < /h1 >, < /p >\n",
    "\n",
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've covered the basics of an HTML document, let's move forward and discuss methods of loading and extracting info from HTML documents in Python. Fortunately, Python offers the package ```BeautifulSoup``` to aid with this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ```BeautifulSoup``` to navigate an HTML document\n",
    "\n",
    "```BeautifulSoup``` transforms an HTML document into a navigable tree structure. This is important and useful to make HTML documents amenable to programming and automated parsing. The primary purpose of ```BeautifulSoup``` is to make working with HTML documents considerably easier. Specifically, ```BeautifulSoup``` is a library in Python that sits on top of HTML, and:\n",
    "\n",
    "1. Offers a variety of ways to search the HTML document\n",
    "2. Allows you to make edits to the HTML document\n",
    "3. Offers techniques to extract information from an HTML document\n",
    "\n",
    "Let's begin by using ```BeautifulSoup``` to analyze ```custom_html_doc```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the simple HTML document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ```BeautifulSoup```, tags correspond to the HTML tag in the original HTML document. The ```html.parser``` of the ```BeautifulSoup``` library is the standard choice to parse a simple HTML formatted string. We will also use the ```prettify()``` method to show the parsed HTML string with indents included, which illustrates how ```BeautifulSoup``` views the HTML document as a tree structure hierarchy of tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   HTML Page Title\n",
      "  </title>\n",
      " </head>\n",
      " <h1>\n",
      "  Head: Important Header: Global News\n",
      " </h1>\n",
      " <br/>\n",
      " <h2>\n",
      "  Head: Less Imporant Header: Global News\n",
      " </h2>\n",
      " <body>\n",
      "  <p class=\"title\">\n",
      "   <b>\n",
      "    Paragraph: Financial news\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   Stocks had a volatile week, where\n",
      "   <a class=\"stock\" href=\"https://finance.yahoo.com/quote/duk/\" id=\"link1\" target=\"_blank\">\n",
      "    DUK\n",
      "   </a>\n",
      "   ,\n",
      "   <a class=\"stock\" href=\"https://finance.yahoo.com/quote/d/\" id=\"link2\" target=\"_blank\">\n",
      "    D\n",
      "   </a>\n",
      "   ,\n",
      "   <a class=\"stock\" href=\"https://finance.yahoo.com/quote/exc/\" id=\"link3\" target=\"_blank\">\n",
      "    EXC\n",
      "   </a>\n",
      "   ,\n",
      "   <a class=\"etf\" href=\"https://finance.yahoo.com/quote/nee/\" id=\"link4\" target=\"_blank\">\n",
      "    NEE\n",
      "   </a>\n",
      "   ,\n",
      "   <a class=\"stock\" href=\"https://finance.yahoo.com/quote/so/\" id=\"link5\" target=\"_blank\">\n",
      "    SO\n",
      "   </a>\n",
      "   ,\n",
      "were all making headlines.\n",
      "  </p>\n",
      "  <p class=\"details\">\n",
      "   End of HTML document.\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# Use the standard html.parser to convert the HTML document into a BeautifulSoup data structure\n",
    "soup = BeautifulSoup(custom_html_doc, 'html.parser')\n",
    "\n",
    "# Print the HTML to the screen with indents included\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that ```BeautifulSoup``` has fully read in the HTML document string ```custom_html_doc```. Let's take a look at a few of the basic ```BeautifulSoup``` features to view the contents inside of ```soup```.\n",
    "\n",
    "First, we can select tags by name using the ```.``` followed by the tag name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"stock\" href=\"https://finance.yahoo.com/quote/duk/\" id=\"link1\" target=\"_blank\">DUK</a>\n"
     ]
    }
   ],
   "source": [
    "# Select the first 'a' tag in the soup (by default the first appearance of a tag is selected)\n",
    "tag = soup.a\n",
    "\n",
    "# Print the tag\n",
    "print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the type of the tag\n",
    "type(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the ```tag``` above has the type ```bs4.element.Tag```. This is the object inside which ```BeautifulSoup``` stores tags.\n",
    "\n",
    "```BeautifulSoup``` tags have attributes and methods. Attributes are essentially properties of the tag object, whereas methods are ways to call functions on the tag object. Let's take a look at a couple of examples of tag properties: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag's name:  a\n",
      "Tag's text:  DUK\n",
      "Tag's parent name:  p\n"
     ]
    }
   ],
   "source": [
    "print(\"Tag's name: \", tag.name) #The name of the tag.\n",
    "print(\"Tag's text: \", tag.text) #Extract the text embedded in the tag.\n",
    "print(\"Tag's parent name: \", tag.parent.name) #Our tag is inside a <p> element. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importantly, tags can have multiple HTML attributes. We can access a these attributes using the ```attrs``` property of the tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'href': 'https://finance.yahoo.com/quote/duk/', 'target': '_blank', 'class': ['stock'], 'id': 'link1'}\n"
     ]
    }
   ],
   "source": [
    "# Show tag attributes\n",
    "print(tag.attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTML attributes define how the element will look (`class`, `id` pointing to a Cascading Style Sheets (CSS) file) and behave (`href` and `target`) in the webpage. We can access and modify these attributes very easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://finance.yahoo.com/quote/duk/\n"
     ]
    }
   ],
   "source": [
    "# Access the hyperlink attribute (use tag like a dictionary to access)\n",
    "print(tag['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'href': 'https://finance.yahoo.com/quote/duk/', 'target': '_blank', 'class': ['stock'], 'id': 'link1', 'new_attr': 100}\n"
     ]
    }
   ],
   "source": [
    "# Add a new attribute (modifies soup)\n",
    "tag['new_attr'] = 100\n",
    "\n",
    "# Look at results\n",
    "print(tag.attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting all tags of a certain kind from an HTML file\n",
    "\n",
    "As we saw earlier, if we simply use ```soup.tag_name```, for some `tag_name` of interest such as a hyperlink tag ```a```, we only receive the first tag back. How do we recieve all the tags in a document of a certain kind?\n",
    "\n",
    "Fortunately, ```BeautifulSoup``` provides the ability to navigate its data structure through a variety of search methods. The one that returns all tags of a given type is ```find_all()```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"stock\" href=\"https://finance.yahoo.com/quote/duk/\" id=\"link1\" new_attr=\"100\" target=\"_blank\">DUK</a>,\n",
       " <a class=\"stock\" href=\"https://finance.yahoo.com/quote/d/\" id=\"link2\" target=\"_blank\">D</a>,\n",
       " <a class=\"stock\" href=\"https://finance.yahoo.com/quote/exc/\" id=\"link3\" target=\"_blank\">EXC</a>,\n",
       " <a class=\"etf\" href=\"https://finance.yahoo.com/quote/nee/\" id=\"link4\" target=\"_blank\">NEE</a>,\n",
       " <a class=\"stock\" href=\"https://finance.yahoo.com/quote/so/\" id=\"link5\" target=\"_blank\">SO</a>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View all hyperlink tags in custom_html_doc\n",
    "soup.find_all('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `find_all()` method returns a list! This is convenient as we can then iterate over them via loops to extract desired information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3:\n",
    "\n",
    "Write a script to print all of the hyperlinks present in ```soup```. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://finance.yahoo.com/quote/duk/\n",
      "https://finance.yahoo.com/quote/d/\n",
      "https://finance.yahoo.com/quote/exc/\n",
      "https://finance.yahoo.com/quote/nee/\n",
      "https://finance.yahoo.com/quote/so/\n"
     ]
    }
   ],
   "source": [
    "print(*[item[\"href\"] for item in soup.find_all('a')],sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this ```BeautifulSoup``` structure greatly simplifies parsing an HTML document. The structure has been encoded in a simple navigable structure, where there are operations to access each subpart of the full document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4:\n",
    "\n",
    "From ```custom_html_doc``` above, use ```BeautifulSoup``` to print the symbol, class, and href attributes for all < a > tags. For example, the first line of output should print:\n",
    "\n",
    "```python\n",
    "AAPL,stock,https://finance.yahoo.com/quote/aapl/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DUK,stock,https://finance.yahoo.com/quote/duk/\n",
      "D,stock,https://finance.yahoo.com/quote/d/\n",
      "EXC,stock,https://finance.yahoo.com/quote/exc/\n",
      "NEE,etf,https://finance.yahoo.com/quote/nee/\n",
      "SO,stock,https://finance.yahoo.com/quote/so/\n"
     ]
    }
   ],
   "source": [
    "print(*[\"{},{},{}\".format(item.text,item[\"class\"][0],item[\"href\"]) for item in soup.find_all('a')],sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing an HTML document corresponding to a real webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we are interested in scraping fundamental stock data off of Yahoo! Finance in order to facilitate making a stock recommendation. We are specifically interested in a company's EPS, PE ratio, and market capitalization.\n",
    "\n",
    "We have pre-downloaded real Yahoo! Finance webpages and saved the HTML files for each of the five energy sector symbols under study. We will first focus on Duke Energy Corporation, an electric power holding company with the stock symbol DUK. Let's render the webpage in the notebook using ```IFrame``` and take a look at its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"400\"\n",
       "            src=\"DUK_Yahoo.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x14f7fe804c8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IFrame will allow us to view the HTML document\n",
    "IFrame(src='DUK_Yahoo.html', width=800, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrolling over the IFrame viewer in the notebook, we see that the webpage for DUK indeed contains a variety of fundamental data quantities, including market capitalization, PE ratio, and EPS (as well as other information like beta, average volume, and forward dividend yield). Hence, this webpage will suffice for our analysis. \n",
    "\n",
    "Let's use ```BeautifulSoup``` to analyze this HTML document and extract the fundamental data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and pass the file handle (here file handle is f) to BeautifulSoup\n",
    "file_name = 'DUK_Yahoo.html'\n",
    "with open(file_name,encoding='utf8') as f:  #Windows users may need to add the option encoding='utf8'\n",
    "    stock_soup = BeautifulSoup(f, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Windows users may need to add the option `encoding='utf8'` to load the webpage into Python.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html class=\"NoJs chrome desktop\" id=\"atomic\" lang=\"en-US\">\n",
      " <head prefix=\"og: http://ogp.me/ns#\">\n",
      "  <script>\n",
      "   window.performance && window.performance.mark && window.performance.mark('PageStart');\n",
      "  </script>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <title>\n",
      "   DUK : Summary for Duke Energy Corporation (Holdin - Yahoo Finance\n",
      "  </title>\n",
      "  <meta content=\"DUK, Duke Energy Corporation (Holdin, DUK stock chart, Duke Energy Corporation (Holdin stock chart, stock chart, stocks, quotes, finance\" name=\"keywords\"/>\n",
      "  <meta content=\"on\" http-equiv=\"x-dns-prefetch-control\"/>\n",
      "  <meta content=\"on\" property=\"twitter:dnt\"/>\n",
      "  <meta content=\"90376669494\" property=\"fb:app_id\"/>\n",
      "  <meta content=\"#400090\" name=\"theme-color\"/>\n",
      "  <meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
      "  <meta content=\"View the basic DUK stock chart on Yahoo Finance. Change the date range, chart type and compare Duke Energy Corporation (Holdin against other companies.\" lang=\"en-US\" name=\"description\"/>\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Look at first 1000 characters to see head of the document (don't want to print too much or it's messy)\n",
    "print(stock_soup.prettify()[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that while the structure of a real webpage is more complex than our sample document from earlier, it still retains the same HTML structure consisting of a series of nested tags each of which identify different elements of the document.\n",
    "\n",
    "One useful tool for debugging and checking the components in a HTML document is to look at the number of occurrences of every type of tag in the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5:\n",
    "\n",
    "Write a script to determine the number of occurences of every tag in ```stock_soup```. Print to the screen a dictionary where each key is a tag name, and the corresponding value for each key is the number of occurrences of that particular tag.\n",
    "\n",
    "**Hint:** You can use `stock_soup.find_all()` to create a list containing ALL tags present in the html file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<meta content=\"on\" http-equiv=\"x-dns-prefetch-control\"/>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_soup.find_all()[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is often used to diagnose missing components of a web page. Let's continue by moving on to extract our first fundamental data quantity of interest - market capitalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "\n",
    "Imagine you are hired as a data scientist who needs to collect data using web scraping every day for a certain period of time. Why would Exercise 5 be helpful in such situation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting market capitalization from the HTML document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing the DUK stock's HTML document, we see there is a table that contains our fundamental data of interest. In HTML, the ```< td >``` tag defines a cell in a table. Since we know the stock market data is stored in a table in the HTML document we choose to look at all the table cell tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td class=\"C(black) W(51%)\" data-reactid=\"38\"><span data-reactid=\"39\">Previous Close</span></td>,\n",
       " <td class=\"Ta(end) Fw(b) Lh(14px)\" data-reactid=\"40\" data-test=\"PREV_CLOSE-value\"><span class=\"Trsdu(0.3s)\" data-reactid=\"41\">85.27</span></td>,\n",
       " <td class=\"C(black) W(51%)\" data-reactid=\"43\"><span data-reactid=\"44\">Open</span></td>,\n",
       " <td class=\"Ta(end) Fw(b) Lh(14px)\" data-reactid=\"45\" data-test=\"OPEN-value\"><span class=\"Trsdu(0.3s)\" data-reactid=\"46\">85.21</span></td>,\n",
       " <td class=\"C(black) W(51%)\" data-reactid=\"48\"><span data-reactid=\"49\">Bid</span></td>,\n",
       " <td class=\"Ta(end) Fw(b) Lh(14px)\" data-reactid=\"50\" data-test=\"BID-value\"><span class=\"Trsdu(0.3s)\" data-reactid=\"51\">84.19 x 900</span></td>,\n",
       " <td class=\"C(black) W(51%)\" data-reactid=\"53\"><span data-reactid=\"54\">Ask</span></td>,\n",
       " <td class=\"Ta(end) Fw(b) Lh(14px)\" data-reactid=\"55\" data-test=\"ASK-value\"><span class=\"Trsdu(0.3s)\" data-reactid=\"56\">84.80 x 800</span></td>,\n",
       " <td class=\"C(black) W(51%)\" data-reactid=\"58\"><span data-reactid=\"59\">Day's Range</span></td>,\n",
       " <td class=\"Ta(end) Fw(b) Lh(14px)\" data-reactid=\"60\" data-test=\"DAYS_RANGE-value\">84.21 - 85.21</td>,\n",
       " <td class=\"C(black) W(51%)\" data-reactid=\"62\"><span data-reactid=\"63\">52 Week Range</span></td>,\n",
       " <td class=\"Ta(end) Fw(b) Lh(14px)\" data-reactid=\"64\" data-test=\"FIFTY_TWO_WK_RANGE-value\">71.96 - 91.35</td>,\n",
       " <td class=\"C(black) W(51%)\" data-reactid=\"66\"><span data-reactid=\"67\">Volume</span></td>,\n",
       " <td class=\"Ta(end) Fw(b) Lh(14px)\" data-reactid=\"68\" data-test=\"TD_VOLUME-value\"><span class=\"Trsdu(0.3s)\" data-reactid=\"69\">3,082,447</span></td>,\n",
       " <td class=\"C(black) W(51%)\" data-reactid=\"71\"><span data-reactid=\"72\">Avg. Volume</span></td>,\n",
       " <td class=\"Ta(end) Fw(b) Lh(14px)\" data-reactid=\"73\" data-test=\"AVERAGE_VOLUME_3MONTH-value\"><span class=\"Trsdu(0.3s)\" data-reactid=\"74\">3,855,570</span></td>,\n",
       " <td class=\"C(black) W(51%)\" data-reactid=\"79\"><span data-reactid=\"80\">Market Cap</span></td>,\n",
       " <td class=\"Ta(end) Fw(b) Lh(14px)\" data-reactid=\"81\" data-test=\"MARKET_CAP-value\"><span class=\"Trsdu(0.3s)\" data-reactid=\"82\">60.317B</span></td>,\n",
       " <td class=\"C(black) W(51%)\" data-reactid=\"84\"><span data-reactid=\"85\">Beta (3Y Monthly)</span></td>,\n",
       " <td class=\"Ta(end) Fw(b) Lh(14px)\" data-reactid=\"86\" data-test=\"BETA_3Y-value\"><span class=\"Trsdu(0.3s)\" data-reactid=\"87\">-0.09</span></td>,\n",
       " <td class=\"C(black) W(51%)\" data-reactid=\"89\"><span data-reactid=\"90\">PE Ratio (TTM)</span></td>,\n",
       " <td class=\"Ta(end) Fw(b) Lh(14px)\" data-reactid=\"91\" data-test=\"PE_RATIO-value\"><span class=\"Trsdu(0.3s)\" data-reactid=\"92\">20.61</span></td>,\n",
       " <td class=\"C(black) W(51%)\" data-reactid=\"94\"><span data-reactid=\"95\">EPS (TTM)</span></td>,\n",
       " <td class=\"Ta(end) Fw(b) Lh(14px)\" data-reactid=\"96\" data-test=\"EPS_RATIO-value\"><span class=\"Trsdu(0.3s)\" data-reactid=\"97\">4.11</span></td>,\n",
       " <td class=\"C(black) W(51%)\" data-reactid=\"99\"><span data-reactid=\"100\">Earnings Date</span></td>,\n",
       " <td class=\"Ta(end) Fw(b) Lh(14px)\" data-reactid=\"101\" data-test=\"EARNINGS_DATE-value\"><span data-reactid=\"102\">Feb 14, 2019</span></td>,\n",
       " <td class=\"C(black) W(51%)\" data-reactid=\"104\"><span data-reactid=\"105\">Forward Dividend &amp; Yield</span></td>,\n",
       " <td class=\"Ta(end) Fw(b) Lh(14px)\" data-reactid=\"106\" data-test=\"DIVIDEND_AND_YIELD-value\">3.71 (4.32%)</td>,\n",
       " <td class=\"C(black) W(51%)\" data-reactid=\"108\"><span data-reactid=\"109\">Ex-Dividend Date</span></td>,\n",
       " <td class=\"Ta(end) Fw(b) Lh(14px)\" data-reactid=\"110\" data-test=\"EX_DIVIDEND_DATE-value\"><span class=\"Trsdu(0.3s)\" data-reactid=\"111\">2018-11-15</span></td>,\n",
       " <td class=\"C(black) W(51%)\" data-reactid=\"113\"><span data-reactid=\"114\">1y Target Est</span></td>,\n",
       " <td class=\"Ta(end) Fw(b) Lh(14px)\" data-reactid=\"115\" data-test=\"ONE_YEAR_TARGET_PRICE-value\"><span class=\"Trsdu(0.3s)\" data-reactid=\"116\">88.06</span></td>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We would like to specifically select the tag that contains the market capitalization information for DUK\n",
    "stock_soup.find_all(\"td\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are so many table cells, we need to narrow our search. In order to find the market capitalization indicator, let's open the HTML file in our browser (or your notebook directly) and inspect the value on the right of `Market Cap` text (use right-click -> inspect). You should see the following HTML code in your browser:\n",
    "\n",
    "```html\n",
    "<td class=\"Ta(end) Fw(b) Lh(14px)\" data-test=\"MARKET_CAP-value\" data-reactid=\"81\"><span class=\"Trsdu(0.3s) \" data-reactid=\"82\">60.317B</span></td>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the market capitalization value is inside a `<td>` element that has the attribute `data-test=\"MARKET_CAP-value`. We can use this identifier to locate the market capitalization value using the method `find()`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'60.317B'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_soup.find(\"td\", {\"data-test\" : 'MARKET_CAP-value'}).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different web pages name different elements differently, so any parsing analysis will need to be customized to a specific website's structure. However, once the rules of a given webpage are established, then parsing becomes much easier as you can employ the power of ```BeautifulSoup```.\n",
    "\n",
    "Let's practice extracting basic elements of an HTML document:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6:\n",
    "\n",
    "Write a script to print all of the available ```data-test``` identifiers present in the table (i.e. present in the first td tag of ```stock_soup```). Your output should print:\n",
    "\n",
    "```\n",
    "PREV_CLOSE-value\n",
    "OPEN-value\n",
    "BID-value\n",
    "ASK-value\n",
    "DAYS_RANGE-value\n",
    "FIFTY_TWO_WK_RANGE-value\n",
    "TD_VOLUME-value\n",
    "AVERAGE_VOLUME_3MONTH-value\n",
    "MARKET_CAP-value\n",
    "BETA_3Y-value\n",
    "PE_RATIO-value\n",
    "EPS_RATIO-value\n",
    "EARNINGS_DATE-value\n",
    "DIVIDEND_AND_YIELD-value\n",
    "EX_DIVIDEND_DATE-value\n",
    "ONE_YEAR_TARGET_PRICE-value\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7:\n",
    "\n",
    "Print the Bid, Ask, Volume, and Average Volume of the stock symbol DUK in ```DUK_Yahoo.html```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search and process multiple HTML documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'd like to automate the parsing task above for all 5 symbols. We'd like to build a function that can parse ANY stock symbol using a systematic method to extract information. This automation will speed up future data analysis and increase productivity. Let's take a look at how to perform this task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of symbols that we'd like to parse\n",
    "symbol_list = ['NEE','DUK','D','SO','EXC'] # list of stock symbols of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_yahoo(symbol):\n",
    "    # Load the previously downloaded file\n",
    "    file_name = symbol + '_Yahoo.html'\n",
    "    with open(file_name) as f:\n",
    "        s = BeautifulSoup(f, 'html.parser')\n",
    "    \n",
    "    # Parse the specific stock data of interest and store in a dictionary object\n",
    "    info_dict = {'MARKET_CAP' : s.find(\"td\", {\"data-test\" : 'MARKET_CAP-value'}).text}\n",
    "    \n",
    "    return info_dict\n",
    "\n",
    "# Loop through all the symbols, applying the parsing function to each of the symbol's corresponding HTML file\n",
    "fundamental_dict = {}\n",
    "for sym in symbol_list:\n",
    "    fundamental_dict[sym] = process_yahoo(sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NEE': {'MARKET_CAP': '83.98B'},\n",
       " 'DUK': {'MARKET_CAP': '60.317B'},\n",
       " 'D': {'MARKET_CAP': '52.519B'},\n",
       " 'SO': {'MARKET_CAP': '47.957B'},\n",
       " 'EXC': {'MARKET_CAP': '44.279B'}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the result\n",
    "fundamental_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that through the use of one function, we can now systematically parse stock information for symbols of our choosing. This has powerful implications for the efficiency of subsequent data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8:\n",
    "\n",
    "Modify the ```process_yahoo()``` function to process and return all three fundamental data quantities of interest, namely the market capitalization, PE ratio, and EPS. The function should return a dictionary where the keys are the ```data-test``` identifiers, and the values are the corresponding fundamental data. Loop through all the symbols, applying the parsing function to each symbol's corresponding HTML file and print each dictionary of fundamental data to the screen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9:\n",
    "\n",
    "After obtaining the preliminary results with the three fundamental data quantities of interest, your manager has requested that you add additional statistics to help determine the liquidity of the stock relative to its average. This will help indicate if a stock has been trading at higher or lower volumes recently. Write a function named ```scrape_volume_ratio``` that takes a symbol name string as an input, and returns the volume ratio, where volume ratio = volume / average volume . All of the data needed to calculate this ratio is available in the HTML documents for each symbol.\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "1. If you need to remove commas from a string, use the replace() method on that string\n",
    "\n",
    "2. Once commas are removed you can change a string to a float using the float() method\n",
    "\n",
    "Once you've define the function loop through all the symbols, apply the parsing function to each symbol's corresponding HTML file. The resulting output should print:\n",
    "\n",
    "{'NEE': 0.9837109088236352,\n",
    " 'DUK': 0.7994789356696934,\n",
    " 'D': 1.2231660648789393,\n",
    " 'SO': 1.0092279816663878,\n",
    " 'EXC': 0.8167456931073666}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've extracted the required fundamental data from our saved HTML documents, let's take a quick look at how to perform web scraping on a live webpage in real time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live web scraping of fundamental stock data\n",
    "\n",
    "**IMPORTANT: You must be careful not to become blocked by a website due to excessive scraping. Do not run a loop that continually scrapes a webpage or the webpage will block you from receiving data due to excessive messaging.**\n",
    "\n",
    "Let's explore scraping data from a Yahoo! Finance page. **(NOTE: Do NOT run this code block as having everyone do it at once may cause you to get blocked.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape data from website\n",
    "site_url='https://finance.yahoo.com/quote/DUK?p=DUK'\n",
    "r = urllib.request.urlopen(site_url)\n",
    "site_content = r.read().decode('utf-8')\n",
    "\n",
    "# Saving scraped HTML to .html file (for later processing)\n",
    "with open('saved_page.html', 'w') as f:\n",
    "    f.write(site_content)\n",
    "\n",
    "# Use html.parser to create soup\n",
    "s = BeautifulSoup(site_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html class=\"NoJs featurephone\" id=\"atomic\" lang=\"en-US\">\n",
      " <head prefix=\"og: http://ogp.me/ns#\">\n",
      "  <script>\n",
      "   window.performance && window.performance.mark && window.performance.mark('PageStart');\n",
      "  </script>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <title>\n",
      "   Duke Energy Corporation (Holdin (DUK) Stock Price, Quote, History &amp; News\n",
      "  </title>\n",
      "  <meta content=\"DUK, Duke Energy Corporation (Holdin, DUK stock chart, Duke Energy Corporation (Holdin stock chart, stock chart, stocks, quotes, f\n"
     ]
    }
   ],
   "source": [
    "# Look at the soup object by using prettify() method\n",
    "print(s.prettify()[:500]) # Only show portion of text as it is very long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we've used the ```urllib``` package to request the website to send us its HTML document. We then passed this HTML document into ```BeautifulSoup``` for parsing. Let's extract the three fundamental data quantities using live web scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabbing data for all five stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(NOTE: Do NOT run this code block as having everyone do it at once may cause you to get blocked.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Symbol: NEE\n",
      "Scraping Symbol: DUK\n",
      "Scraping Symbol: D\n",
      "Scraping Symbol: SO\n",
      "Scraping Symbol: EXC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MARKET_CAP</th>\n",
       "      <th>PE_RATIO</th>\n",
       "      <th>EPS_RATIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>65.251B</td>\n",
       "      <td>67.97</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DUK</th>\n",
       "      <td>70.084B</td>\n",
       "      <td>21.28</td>\n",
       "      <td>4.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXC</th>\n",
       "      <td>46.617B</td>\n",
       "      <td>20.50</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEE</th>\n",
       "      <td>113.405B</td>\n",
       "      <td>33.34</td>\n",
       "      <td>6.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SO</th>\n",
       "      <td>64.679B</td>\n",
       "      <td>14.57</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MARKET_CAP PE_RATIO EPS_RATIO\n",
       "D      65.251B    67.97      1.20\n",
       "DUK    70.084B    21.28      4.52\n",
       "EXC    46.617B    20.50      2.34\n",
       "NEE   113.405B    33.34      6.96\n",
       "SO     64.679B    14.57      4.25"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol_list = ['NEE','DUK','D','SO','EXC'] # stocks of interest\n",
    "\n",
    "def scrape_yahoo(symbol):\n",
    "    symbol_url='https://finance.yahoo.com/quote/' + symbol\n",
    "    MARKET_CAP= \"MARKET_CAP\"\n",
    "    PE_RATIO = \"PE_RATIO\"\n",
    "    EPS_RATIO = \"EPS_RATIO\"\n",
    "    \n",
    "    # Scrape\n",
    "    r = urllib.request.urlopen(symbol_url)\n",
    "    c = r.read().decode('utf-8')\n",
    "    s = BeautifulSoup(c, 'html.parser')\n",
    "    \n",
    "    info_dict = {MARKET_CAP : s.find(\"td\", {\"data-test\" : MARKET_CAP+'-value'}).text,\n",
    "                 PE_RATIO : s.find(\"td\", {\"data-test\" : PE_RATIO+'-value'}).text,\n",
    "                 EPS_RATIO : s.find(\"td\", {\"data-test\" : EPS_RATIO+'-value'}).text\n",
    "                }\n",
    "    \n",
    "    return info_dict\n",
    "\n",
    "# Scrape the data, and store in a dictionary\n",
    "symbol_dict = {}\n",
    "for symbol in symbol_list:\n",
    "    print(\"Scraping Symbol: \" + symbol)\n",
    "    symbol_dict[symbol] = scrape_yahoo(symbol)\n",
    "    \n",
    "# Display the parsed data\n",
    "fundamental_df = pd.DataFrame.from_dict(symbol_dict, orient='index')\n",
    "fundamental_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've acquired the data, here is how the data is used to make recommendations:\n",
    "\n",
    "1. A higher EPS value is seen as more attractive from an investment standpoint\n",
    "2. PE ratios are often compared among stocks in the same industry. Within a single industry, the lower the PE ratio, the more undervalued it generally is\n",
    "3. Market capitalization is important as it signals the size of the company. Smaller companies are more speculative and generally riskier\n",
    "\n",
    "The firm would like to invest in the stock with the lowest PE ratio and the highest EPS which still has a market capitalization of at least 10 billion. Recall that from the static HTML files:\n",
    "\n",
    "```\n",
    "{'NEE': {'MARKET_CAP': '83.98B', 'PE_RATIO': '10.00', 'EPS_RATIO': '17.57'},\n",
    " 'DUK': {'MARKET_CAP': '60.317B', 'PE_RATIO': '20.61', 'EPS_RATIO': '4.11'},\n",
    " 'D': {'MARKET_CAP': '52.519B', 'PE_RATIO': '14.57', 'EPS_RATIO': '4.80'},\n",
    " 'SO': {'MARKET_CAP': '47.957B', 'PE_RATIO': '19.45', 'EPS_RATIO': '2.40'},\n",
    " 'EXC': {'MARKET_CAP': '44.279B', 'PE_RATIO': '11.91', 'EPS_RATIO': '3.84'}}\n",
    "```\n",
    " \n",
    "Here we see the best investment for the firm (using the metrics outlined) is to invest in NEE, as it has the lowest PE ratio and the highest EPS, while maintaining a market capitalization above 10 billion.\n",
    "\n",
    "Given that we just scraped live data for these stocks, let's take a look to see if our investment decision has changed with the updated data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "In this case, we've introduced a framework for automating web scraping tasks to produce a stock recommendation based on fundamental data. This general web scraping framework can be customized to address a user's unique needs on data requirements and parsing requirements.\n",
    "\n",
    "We found that web scraping the HTML document for the five energy sector symbols required an analysis of the structure and content of the HTML documents to parse out the three fundamental data quantities of interest: market capitalization, PE ratio, and EPS. We utilized these three statistics alongside the firm's investment objectives to arrive at a recommendation to invest in the stock NEE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Takeaways\n",
    "\n",
    "In this case, you learned the basics of HTML, ```BeautifulSoup```, and `urllib`. You found that ```BeautifulSoup``` greatly simplifies HTML parsing and extraction of useful information.\n",
    "\n",
    "```BeautifulSoup``` is a library that has a vast array of capabilites that extend far beyond what is covered here. Hence, we encourage anyone looking to do more advanced web scraping to explore some of the more complex methods available in the library. The contents covered in this case should serve as an excellent base to build upon."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
