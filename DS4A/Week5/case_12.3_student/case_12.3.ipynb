{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How can we build a company database to handle product sales end-to-end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals (2 min)\n",
    "\n",
    "In this case, we will move away from using SQL queries to extract data and talk about how to design a database. This will be put into practice by creating a database in the cloud using Amazon AWS's ```RDS``` service.\n",
    "\n",
    "The case will involve interacting with a database in the cloud so there will also be ample use of the terminal to communicate with the server. The focus of the case will be on the design and creation of databases and so there will be more discussion than usual but simple queries will be done to practice querying via the terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction (5 min)\n",
    "\n",
    "**Business Context.** You are a data analyst for the same large financial services firm as in the previous case. The firm was pleased with your analysis and now the see they value of having databases that can easily be queried using SQL. It would therefore like to move its data, which is currently stored as CSV files, onto a proper database.\n",
    "\n",
    "**Business Problem.** The business would like you to **create a database to house its existing data and add a few more data tables to track additional information they are interested in**.\n",
    "\n",
    "**Analytical Context.** The data is split across three tables: \"Agent\", \"Call\", and \"Customer\", which sit on CSV files. We will be creating a database and then loading the data from these CSV files into that database.\n",
    "\n",
    "The case is sequenced as follows: you will (1) learn the fundamentals of database management systems; (2) setup an RDS instance on Amazon AWS; (3) use SQL to set up a new database with tables in PostgreSQL; (4) query our newly created database to answer business questions; and finally (5) design enhancements to our database to fit expanded business requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database management systems (10 min)\n",
    "\n",
    "So far, you have been using SQL via `SQLAlchemy` to interact with databases. But databases by themselves are quite useless when there is more than one person involved in writing data to it. Rather, we use **database management systems** in order to manage databases properly. All the examples mentioned in the previous case (SQL Server, Oracle, PostgreSQL) are in fact database management systems (going forward, let’s refer to them as DBMS) and not databases.\n",
    "\n",
    "But why did these DBMS come into existence? Why wasn’t a database enough? To answer that, imagine our previous example where we mentioned the phone book record, where you keep track of all your friends and their phone numbers, but now on a text file on your computer. So you have the following file:\n",
    "\n",
    "<img src=\"images/m1_1.jpg\" width=\"400\">\n",
    "\n",
    "That looks fine and it works as you'd expect. But now imagine you upload a YouTube video of yourself dancing to a new song and, due to your amazing dancing moves, that video goes viral. As a result, you become the most popular person in your neighborhood, and everybody wants to be your friend. Since you want to keep track of all of your new friends' phone numbers, you decide to add all these new contacts to your “phones.txt” file. But given the number of new friends you are making, you ask your sister to help you with adding your new friends to the list. \n",
    "\n",
    "Being a tech-savvy guy, you share the folder where the file is located on your home network and create a shortcut to it on your sister’s laptop. She opens the file and you both start adding new contacts to the file at the same time. Each of you individually save the file when you are finished and go to sleep. But when you wake up the next morning, you notice that half of all the contacts are gone!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: (5 min)\n",
    "\n",
    "What do you think went wrong here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** Although both save operations worked properly and were actually saved to the database, the first person to save the file later had their version overwritten by the second save request, using only the data inputted by the second person. Preventing this (and other even more complex and dangerous scenarios) is the reason why DBMS were born."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a cloud database using RDS and importing data (45 min)\n",
    "\n",
    "Let's set up a real database and so that we can see the different design considerations. To do this, we'll be using Amazon AWS's ```RDS``` product. Once we have the database created, we will connect to it using the `psql` command which should have been installed in the previous case.\n",
    "\n",
    "1. Log into your AWS account and select \"RDS\" from the service list. You should see a screen like the one below, where you can hit the \"Create database\" button:\n",
    "\n",
    "![Create Database](images/create_db.png)\n",
    "\n",
    "2. The next option you'll see asks you if you want to use \"standard create\" or \"easy create\". Easy might sound tempting, but **choose \"standard\"** as we'll have to set up our database for public use so we can connect to it locally.\n",
    "\n",
    "3. Choose \"PostgreSQL\" as the database type, leave the version at the default AWS has chosen for you (11.6-R1 at the time of writing), and choose \"Free Tier\"\n",
    "\n",
    "4. Under \"Storage\" turn off \"Storage autoscaling\". This will prevent any unexpected future charges.\n",
    "\n",
    "![Turn off autoscaling](images/autoscale.png)\n",
    "\n",
    "5. Under the next section, choose a name for your database instance. Remember this is the machine that is hosting the database software, not the database itself (one RDS instance can host many databases), so I'm calling mine `ds4a-demo-instance` to reflect this, although we'll only be creating a single database for now. \n",
    "\n",
    "6. You can leave the master username as `postgres` and ask RDS to autogenerate a password (we'll be able to see this password at the next step):\n",
    "\n",
    "![Set DB password](images/set_db_password.png)\n",
    "\n",
    "7. You can leave the next settings as their defaults until you get to the \"Connectivity\" section. Usually, you'll set up an RDS instance to play with other infrastructure within your AWS account, such as EC2 servers. In our case, we want to push data in and out of the database directly from our local machine as the client, so we'll have to set our database up for \"public access\". This is generally less secure, but we'll add some firewall rules in a bit to make sure that only we can access it:\n",
    "\n",
    "      * Expand the \"Additional connectivity configuration\" section\n",
    "\n",
    "      * Set \"publicly accessible\" to \"Yes\"\n",
    "\n",
    "      * Under \"VPC security group\", choose to \"Create new\", and give it a name like `allow-local-access`. This will create a firewall rule that will allow you to connect to your database on port 5432 (the default for PostgreSQL) using your current IP address. If you are using public WiFi, a hotspot, or if you think your IP address is likely to change soon for any reason, note that you'll have to modify this security group any time your IP address changes:\n",
    "\n",
    "![Create Security Group](images/create-sec-group.png)\n",
    "\n",
    "8. Press the \"Create database\" button in the bottom right, and you'll be taken back to the overview page where you can see your database being created. At the top, there'll be a notification where you can press \"View credential details\" to access your master password that was automatically generated. **Take note of this as you can only see it once.** Note: this creates a database in the default VPC. If your default VPC is not configured for DNS connections, you will need to create a new VPC. Please see 'Appendix 1: Troubleshooting RDS creation' for instructions on how to do achieve this.\n",
    "\n",
    "![View credentials](images/view_creds.png)\n",
    "\n",
    "9. Once your database becomes \"available\" (you might need to press the \"refresh\" button indicated below to see the change), you can connect to it. Click on the name of the database (`ds4a-demo-instance` in our example), to find out the connection details:\n",
    "\n",
    "![DB available](images/db-available.png)\n",
    "\n",
    "10. Once you click on the database, you should see the endpoint that you need on a screen similar to the one shown below. You need this endpoint to connect to the database from your local machine.\n",
    "\n",
    "![DB Endpoint](images/db-endpoint.png)\n",
    "\n",
    "11. Locally, open a terminal and run the following command, substituting [endpoint] with the one that you noted from the RDS console above.\n",
    "\n",
    "```bash\n",
    "psql -h [endpoint] -U postgres\n",
    "```\n",
    "\n",
    "This will connect to our instance's default database using the master username. It will prompt you for the password and you can enter the autogenerated password from above. You should now see a SQL prompt, similar to the image below:\n",
    "\n",
    "![PSQL prompt](images/psql-prompt.png)\n",
    "\n",
    "We've successfully created a cloud database and connected to it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up our database (10 min)\n",
    "\n",
    "Let's proceed by setting up our database in Amazon RDS:\n",
    "\n",
    "1. In the SQL shell, run the following commands to create a database, create a user to manage our database, and give privileges on our new database to our new user. Replace [password] with your own choice of password:\n",
    "\n",
    "```SQL\n",
    "create database ds4a_demo_db;\n",
    "create user ds4a_demo_user with login encrypted password '[password]';\n",
    "grant all privileges on database ds4a_demo_db to ds4a_demo_user;\n",
    "\\q\n",
    "```\n",
    "\n",
    "Here, `\\q` closes the connection so you can re-open it under a different user.\n",
    "\n",
    "2. Run the following command. It is similar to the one we used before to connect but now specifies both our custom user and our custom database. Once again, substitute [endpoint] with the one you see in the RDS console.\n",
    "\n",
    "```SQL\n",
    "psql -h [endpoint] -U ds4a_demo_user -d ds4a_demo_db\n",
    "```\n",
    "\n",
    "3. Put in the new password that you entered in the SQL statement in step 1 instead of the master password that AWS automatically generated for us.  You'll see a very similar prompt, but with the `ds4a_demo_db=>` prompt instead of `postgres=>`:\n",
    "\n",
    "![demo prompt](images/demo-prompt.png)\n",
    "\n",
    "The next thing we need to do is to create tables to house our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Definition Language (DDL) statements in SQL (5 min)\n",
    "\n",
    "**Data Definition Language (DDL)** statements are used to create, modify, and remove database objects themselves as well as the data within them. The most important statement in DDL space is the `CREATE TABLE` command. To create a table, you need to provide the table's name, its columns, and each column's type. For example, the SQL command below creates a table called `Product`, with an `INTEGER` field called `ProductID` and a `VARCHAR(20)` (string with up to 20 characters) field called `ProductName`:\n",
    "\n",
    "```SQL\n",
    "CREATE TABLE Product(ProductID INT, ProductName varchar(20))\n",
    "```\n",
    "\n",
    "Once you have created a table, you can use certain DML statements used to manipulate data in the tables themselves (rather than merely in the outputs of queries, as you did in the previous case). These commands are:\n",
    "\n",
    "1. `INSERT`: to insert data into a table\n",
    "2. `UPDATE`: to update existing data within a table\n",
    "3. `DELETE`: to delete records from a database table\n",
    "\n",
    "Below is additional information on each:\n",
    "\n",
    "1. The INSERT INTO statement is used to add rows to a table. Its syntax is as follows:\n",
    "\n",
    "    ```SQL\n",
    "    INSERT INTO table_name (column1, column2, column3,...)\n",
    "    VALUES (value1, value2, value3,...)\n",
    "    ```\n",
    "\n",
    "    Alternatively, if you are adding values for all the columns of the table, you do not need to specify the column names.\n",
    "\n",
    "\n",
    "2. The `UPDATE` statement is used to modify existing records in a table. You indicate which table you are updating, and then give the columns you want modified followed by a condition (a `WHERE` clause) that specifies which record(s) should be updated. If you omit the `WHERE` clause, all records in the table will be updated!\n",
    "\n",
    "```SQL\n",
    "UPDATE table_name\n",
    "SET column1 = value1, column2 = value2,...\n",
    "WHERE condition;\n",
    "```\n",
    "\n",
    "3. The `DELETE` statement is used to delete existing records in a table:\n",
    "\n",
    "```SQL\n",
    "DELETE FROM table_name\n",
    "WHERE condition\n",
    "```\n",
    "\n",
    "Similarly to the syntax for `UPDATE`, the `WHERE` clause specifies which record(s) should be deleted. **If you omit the `WHERE` clause, all records in the table will be deleted, so be VERY careful with this statement!**\n",
    "\n",
    "The below table summarizes the differences between DDL and DML statements:\n",
    "\n",
    "![DDL Statements](./images/ddl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: (5 min)\n",
    "\n",
    "Set up a new database with the following tables and column details. You should work on the queries in a text editor and copy and paste the commands to your `psql` connection:\n",
    "\n",
    "1. Table Name: `Customer` \n",
    "   Columns:\n",
    "      * **CustomerID** INT, this will be the primary key of the table\n",
    "      * **Name** VARCHAR(50)\n",
    "      * **Occupation** VARCHAR(50)\n",
    "      * **Email** VARCHAR(50)\n",
    "      * **Company** VARCHAR(50)\n",
    "      * **PhoneNumber** VARCHAR(20)\n",
    "      * **Age** INT\n",
    "\n",
    "2. Table Name: `Agent`\n",
    "   Columns:\n",
    "      * **AgentID** INT, this will be the primary key of the table\n",
    "      * **Name** VARCHAR(50)\n",
    "\n",
    "3. Table Name: `Call`\n",
    "   Columns:\n",
    "      * **CallID** INT, this will be the primary key of the table\n",
    "      * **AgentID** INT\n",
    "      * **CustomerID** INT\n",
    "      * **PickedUp** SMALLINT\n",
    "      * **Duration** INT\n",
    "      * **ProductSold** SMALLINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** One possible solution is given below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "CREATE TABLE Customer(\n",
    "    CustomerID INT primary key,\n",
    "    Name VARCHAR(50),\n",
    "    Occupation VARCHAR(50),\n",
    "    Email VARCHAR(50),\n",
    "    Company VARCHAR(50),\n",
    "    PhoneNumber VARCHAR(20),\n",
    "    Age INT\n",
    ")\n",
    "\n",
    "CREATE TABLE Agent(\n",
    "    AgentID INT primary key,\n",
    "    Name VARCHAR(50)\n",
    ")\n",
    "\n",
    "CREATE TABLE Call(\n",
    "    CallID INT primary key,\n",
    "    Agentid INT,\n",
    "    Customerid INT,\n",
    "    Pickedup SMALLINT,\n",
    "    Duration INT,\n",
    "    ProductSold SMALLINT\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pushing sample data into RDS (10 min)\n",
    "\n",
    "Let's now push our data onto RDS. Run the command below, again substituting [endpoint] with the actual endpoint you used above. Make sure that the `Customer.csv` file is located in the same directory that you run the `psql` command from:\n",
    "\n",
    "```bash\n",
    "psql -h [endpoint] -U ds4a_demo_user -d ds4a_demo_db -c \"\\copy Customer from 'Customer.csv' with (format csv, header true, delimiter ',');\"\n",
    "```\n",
    "\n",
    "The first part of the command is the same one we used before to open a SQL shell. Here we also pass the `-c` flag which allows us to specify a SQL command to be run on the database. Because our shell has permissions to access our local file system, but our database doesn't, running the command like this means we won't have problems with permissions. In the `\\copy` command, we specify which table we want to populate (`Customer`), where the local file is (`Customer.csv`), that our file is in CSV format, that it has a header, and that we are using a comma as a delimiter. \n",
    "\n",
    "This should prompt you for the password (again, use the one that you created for the `ds4a_demo_user`). It will then let you know how many rows it has successfully imported, similar to the image below:\n",
    "\n",
    "![Copy successful](images/copy-successful.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: (5 min)\n",
    "\n",
    "Do the above steps for the `Agent`, `Call`, and `Customer` tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** One possible solution is given below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "psql -h [endpoint] -U ds4a_demo_user -d ds4a_demo_db -c \"\\copy Agent from 'Agent.csv' with (format csv, header true, delimiter ',');\"\n",
    "\n",
    "psql -h [endpoint] -U ds4a_demo_user -d ds4a_demo_db -c \"\\copy Call from 'Call.csv' with (format csv, header true, delimiter ',');\"\n",
    "\n",
    "psql -h [endpoint] -U ds4a_demo_user -d ds4a_demo_db -c \"\\copy Customer from 'Customer.csv' with (format csv, header true, delimiter ',');\"\n",
    "```\n",
    "\n",
    "where `CSV file path` is replaced with wherever you are storing the files locally on your computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using our data tables to answer business questions (30 min)\n",
    "\n",
    "Now that we have set up the exact tables we want, we can reap the rewards of our labor and write DML statements to extract info and answer relevant business questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: (15 min)\n",
    "\n",
    "Two metrics of sales agent performance that your firm is interested in are: 1) for each agent, how many seconds on average does it take them to sell a product when successful; and 2) for each agent, how many seconds on average do they stay on the phone before giving up when unsuccessful. Write a query which computes this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** One possible solution is given below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT a.Name,\n",
    "SUM(\n",
    "   CASE\n",
    "       WHEN ProductSold = 0 THEN Duration\n",
    "       ELSE 0\n",
    "   END)/SUM(\n",
    "   CASE\n",
    "       WHEN ProductSold = 0 THEN 1\n",
    "       ELSE 0\n",
    "   END)\n",
    "AS avgWhenNotSold ,\n",
    "SUM(\n",
    "   CASE\n",
    "       WHEN ProductSold = 1 THEN Duration\n",
    "       ELSE 0\n",
    "   END)/SUM(\n",
    "       CASE WHEN ProductSold = 1 THEN 1\n",
    "       ELSE 0\n",
    "   END)\n",
    "AS avgWhenSold\n",
    "FROM call c\n",
    "JOIN agent a ON c.AgentID = a.AgentID\n",
    "GROUP BY a.Name\n",
    "ORDER BY 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: (15 min)\n",
    "\n",
    "In order to incentivize its sales agents, the firm is offering a bonus for the agents who manage to close a sale the fastest. Write a query which gives, for each agent, the duration of that agent's quickest sale and the customer name it was sold to. If there are ties (i.e. for the same agent, two sales with the same duration), pick the one with the highest `CustomerID` value to be part of your query results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** One possible solution is given below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT a.name AS AgentName, cu.Name AS CustomerName, x.Duration\n",
    "FROM\n",
    "(\n",
    "   SELECT ca.AgentID, ca.Duration, max(CustomerID) AS cid\n",
    "   FROM\n",
    "   (\n",
    "       SELECT AgentID, min(Duration) as fastestcall\n",
    "       FROM Call\n",
    "       WHERE ProductSold = 1\n",
    "       GROUP BY AgentID\n",
    "   ) min\n",
    "   JOIN Call ca ON ca.AgentID = min.AgentID AND ca.Duration = min.fastestcall\n",
    "   WHERE ProductSold = 1\n",
    "   GROUP BY ca.AgentID, ca.Duration\n",
    ") x\n",
    "JOIN Agent a ON x.AgentID = a.AgentID\n",
    "JOIN Customer cu ON cu.CustomerID = x.cid\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A word about DBMS properties (5 min)\n",
    "\n",
    "Every database must exhibit certain properties in order to guarantee that the data inside it is reliable. The **ACID properties** refer to four fundamental transactional properties of DBMS, and stand for “Atomicity, Consistency, Isolation, and Durability”. If a tool claims to be a DBMS and does not exhibit all of these properties, then it is not a DBMS.\n",
    "\n",
    "Here is a visual explanation of the ACID properties:\n",
    "\n",
    "![Acid Properties](./images/acid.png)\n",
    "\n",
    "The properties can be quickly explained as follows:\n",
    "\n",
    "1. **Atomicity**: Means “all or nothing”. Let's take the bank transfer example again; remember that transferring money from Account A to Account B is two separate operations. If the bank system fails right after the money leaves Account A but before it enters Account B, then that's not \"all or nothing\" (and it's bad). Atomicity guarantees that a unit of work is fully executed or not executed at all.\n",
    "\n",
    "2. **Consistency**: Means that the DBMS prevents database corruption by guaranteeing that the database is always valid according to the rules on which it was defined (essentially, no \"rogue\" databases not following instructions).\n",
    "\n",
    "3. **Isolation**: Ensures that concurrent execution of transactions leaves the database in the same state as would have been obtained if the transactions had been executed sequentially. This is especially important in distributed database systems.\n",
    "\n",
    "4. **Durability**: This property guarantees that once the transaction is committed to the database, it is durable. Basically, this means that you cannot receive an “OK” message if something bad (like a power failure) happens between when the changes are written from the memory buffer and when they are written to the disk (causing the transaction to fail).\n",
    "\n",
    "NoSQL databases, on the other hand, support a different set of properties called BASE, which stands for “Basically Available, Soft state, Eventually consistent”. We will not get into this here, except to mention that \"Eventually consistent\" means that “eventually” consumers may not see the latest version of the data, which may or may not be a problem depending on the context. If you would like to learn more, feel free to look up the CAP Theorem for distributed databases systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database design (40 min)\n",
    "\n",
    "The business is happy with what you've done so far, and would like to incorporate more elements of its end-to-end sales process into the database you've created. However, this added complexity is likely to serve up some database design challenges. What are some important principles we should keep in mind as we help the business build this out?\n",
    "\n",
    "Let's revisit the phones and cities example from earlier, where you wanted to record the city where each one of your contacts lives. This seems straightforward enough - just add a new column to your `phones` table called `city` and record the name of the correct city in each cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6: (5 min)\n",
    "\n",
    "What sorts of problems and/or inefficiencies do you think this method might cause?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** There are several, but some example include:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. It wastes a lot of space. For example, suppose that you have 1000 friends in this database who all live in \"San Francisco\". The database would have to store the same exact piece of information, 100 times, with each instance consuming 13 characters of space.\n",
    "2. If you decide to change “San Francisco\" to “San Francisco, CA”, the database would have to change it in 1000 different locations.\n",
    "3. If you accidentally write “san francisco” for one of the cells, then even though you know that it is the same as \"San Francisco\", the database treats them differently. A similar situation happens with typos.\n",
    "4. If you write a query with a `WHERE` clause saying `WHERE city = “New York City”`, you may miss rows if either (2) or (3) above are true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix these inefficiencies and problems, we use a concept called **normal forms**. Designing your database based on normal forms rules will make it much easier to scale and maintain. There are a total of 6 normal forms, plus some intermediaries and alternatives in between. You don't need to know these now, except First Normal Form (1NF), which we will discuss below. We suggest you spend some time on Google reading about these forms, but you’ll only really understand them with practice and experience, so there is no point memorizing them now. The process of representing a database in terms of relations in normal forms is known as **database normalization**.\n",
    "\n",
    "1NF says that:\n",
    "\n",
    "*“A relation is in first normal form if and only if the domain of each attribute contains only atomic (indivisible) values, and the value of each attribute contains only a single value from that domain.*\n",
    "\n",
    "It's really unclear if that's even English, so we'll break it down:\n",
    "\n",
    "1. Individual tables should not contain repeat information (i.e. non-ID info)\n",
    "2. If there was originally repeated information, create a separate table to group that info\n",
    "3. Identify each set of repeated information with a primary key\n",
    "\n",
    "For instance, if we had information about vendors and the banks they were using, this process would look like the below:\n",
    "\n",
    "![Normal forms](./images/normal_forms.gif)\n",
    "\n",
    "Going back to our phones and cities example, instead of writing \"San Francisco\" in each row of the `phones` table, we can create a `cities` table, which has an ID and name for each city. We can then store the city ID instead of the name in the `phones` table, using it as a foreign key:\n",
    "\n",
    "<img src=\"images/m1_2.jpg\" width=\"600\">\n",
    "\n",
    "Notice that John and Rita live in New York, while Paul lives in Boston, but the `phones` table only has the ID of the city each of them live in, rather than information about the city itself. Also note that we added an ID to the `phones` table to uniquely identify each friend (which is also consistent with the 1NF definition).\n",
    "\n",
    "This reduces necessary storage space (e.g. only a number will be stored in each row of `phones` instead of the entire city name), and also makes updates to the data much easier (e.g. only one row in `cities` table has to be updated if you want to change \"San Francisco\" to \"San Francisco, CA\").\n",
    "\n",
    "### Question: (5 min)\n",
    "\n",
    "What are your thoughts on the name of the `phones` table? Is it really a table used to store phone numbers? What if a friend has more than one phone number? How would you proceed? Discuss this with people around you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7: (7 min)\n",
    "\n",
    "In order to accommodate the increased complexity of its end-to-end product sales efforts, your firm would like you to set up new tables and/or modify existing tables in your newly-created database. The additional features are as follows:\n",
    "\n",
    "1. Each product has a name, and customers can buy multiple products\n",
    "2. Some products are upgrades to others; i.e. you must purchase the baselines version before you can purchase upgrades. For the sake of simplicity, assume each product can be upgraded from at most one other product\n",
    "3. You need to keep track of customers' purchases of the various products\n",
    "\n",
    "How would you set up new tables and/or modify existing tables to accommodate for these requirements? Write SQL queries that will accomplish this task. You will need the following additional DDL statements:\n",
    "\n",
    "The `ALTER TABLE` statement is used to add, delete, or modify columns in an existing table or to add and drop constraints on an existing table.\n",
    "\n",
    "1. Adding a column:\n",
    "\n",
    "```SQL\n",
    "ALTER TABLE \"tablename\"\n",
    "ADD \"newcolumn\" \"datatype\"\n",
    "```\n",
    "\n",
    "2. Dropping a column:\n",
    "\n",
    "```SQL\n",
    "ALTER TABLE \"tablename\"\n",
    "DROP COLUMN \"columnname\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** An ideal design would be as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. A `Product` table:\n",
    "    - `ProductID` as a unique primary key (reasonable to assume it is an integer)\n",
    "    - `ProductName` as the name of the product (string, reasonable to asume VARCHAR(50))\n",
    "    - `UpgradedFromProductID` as the ID of the product from which this is an upgrade\n",
    "\n",
    "\n",
    "2. Modify the `Call` table:\n",
    "    - Add `ProductID` as a foreign key\n",
    "    \n",
    "An appropriate set of SQL queries for this is as follows:\n",
    "\n",
    "```SQL\n",
    "CREATE TABLE Product(\n",
    "    ProductID INT primary key,\n",
    "    ProductName VARCHAR(50),\n",
    "    UpgradedFromProductID INT\n",
    ")\n",
    "\n",
    "ALTER TABLE call\n",
    "ADD ProductID INT\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: (5 min)\n",
    "\n",
    "Discuss this with your classmates. How would you modify your design in Exercise 7 if:\n",
    "\n",
    "1. a product could be upgraded from multiple previous products\n",
    "2. certain products can only be sold at certain periods of time (i.e. product availability is seasonal). You can assume this set of periods is not too large\n",
    "3. you had to keep track of the times when the products are avaiable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8: (15 min)\n",
    "\n",
    "The business would like you to extend your database design work into a brand-new data warehouse that will be used for real-time reporting. The data warehouse will be populated by a daily Extract-Transform-Load (ETL) process that your team will also write. The main source of data comes from the current end-to-end sales process. In addition to the tables in your previous design, here is a list of additional tables you think you will need:\n",
    "\n",
    "1. `Order`: contains information about the sales date, the expected delivery date, the customer that bought the product, the total value of the sale, the delivery address, the cargo company, and the driver that will perform the delivery\n",
    "2. `OrderItems`: contains information about each item in the order such as: the order item ID, the ID of the order, the product ID, the item quantity, and the product price (note that the same product can be sold for different prices across different orders)\n",
    "3. `ProductCategory`: contains the description of the category\n",
    "\n",
    "How would you design your datawarehouse to maximize read performance? Work on this with a partner. Note that in order to optimize read performance, it is NOT necessarily best to follow normal form protocol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** One possible solution is given below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Have one `Order` table that contains information about orders and items, where each row is indexed by `OrderID` and `OrderItemID`. Although this does not conform with normal form protocol, a reporting system that performs a lot of reads will almost certainly want to extract information about both orders and items so this avoids a lot of expensive Cartesian products and JOINs of two tables that will be tied at the hip.\n",
    "2. Add a detail key `ItemTotal` to each row of the `Order` table, which is defined as `ItemQuantity` times `ProductPrice`, as this field will probably be important for reporting, which is part of read performance.\n",
    "3. Add `ProductCategoryID` as a foreign key to the `Product` table\n",
    "4. Break out the delivery address field of `Order` into separate components such as `State`, `City`, `Zipcode`, etc. Aggregation based on location is a very common sort of reporting function and having to parse addresses every time is a pain unless the groupings are already well-defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic properties of data warehouses (5 min)\n",
    "\n",
    "We briefly mentioned the term **data warehouse** in the previous exercise, but what is it really? Data warehousing is a process for collecting and managing data from varied sources to provide meaningful business insights. A data warehouse is typically used to connect and analyze business data from heterogeneous sources and provide meaningful reports on the same to the end users:\n",
    "\n",
    "![Data Warehouse](./images/datawarehouse.jpg)\n",
    "\n",
    "Unlike databases, data is often de-normalized in a data warehouse. In professional settings, sometimes you may be required to read data from a data warehouse instead of a database. We'll not go much deeper into it right now, but we’ll drop in a few bullet points so that you are familiar with the concept if it comes up in a professional setting:\n",
    "\n",
    "1. Data warehouses are mainly used for reporting as opposed to day-to-day transactions\n",
    "    * As such, they are optimized for read rather than write operations\n",
    "    * If you want to go deeper on this, read about OLTP versus OLAP systems\n",
    "    \n",
    "    \n",
    "2. Data warehouses run on different hardware (servers) than the database does\n",
    "    * Usually, that hardware is a lot more robust than the one the database runs\n",
    "    \n",
    "    \n",
    "3. Data warehouses are usually updated via Extract-Transform Load (ETL) \"batch\" jobs\n",
    "    * For example, once a day all changes from the database (compared to the previous day) are propagated to the data warehouse\n",
    "    \n",
    "    \n",
    "4. Data warehouses don’t throw away all the normalization that was done at the database level, they just change them a bit to reduce the number of `JOIN`s necessary to run the queries\n",
    "    * In other words, they sacrifice storage efficiency in favour of performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions (2 min)\n",
    "\n",
    "In this case, you ventured outside of SQL in a Python environment and used your newfound knowledge to expand the scope of databaases within a financial products firm. First, you learned about database management systems. You then set up an initial PostgreSQL database in AWS RDS and made upgrades to it based on more complex business requirements. You also performed queries on your new database to answer relevant business questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways (5 min)\n",
    "\n",
    "In this case, we learned the basics of setting a database management system in the cloud using Amazon ```RDS```. We also built a foundation of basic DDL ```SQL``` commands to build databases and their tables. We finished the case by talking about how databases are structured in real world applications. Specifically we:\n",
    "\n",
    "1. Created an ```RDS``` instance on Amazon AWS\n",
    "2. Connected to a database using ```psql```\n",
    "3. Performed ```CREATE TABLE``` queries\n",
    "4. Learned about the ```ALTER TABLE``` and ```DROP``` queries\n",
    "5. Discussed database normal forms and data warehouse\n",
    "\n",
    "Databases are a core technology when building data science applications and putting them in production. More \n",
    "importantly, a bad database design can lead to convoluted structures that make your data extraction queries very slow.  While you probably will not be designing the database as a data scientist, it is helpful to know how databases are typically structured so that you may pick up a new database structure quickly.\n",
    "\n",
    "To further expand on the concepts taught in this case, you should go through the ```RDS``` creation step again and investigate all the configuration options. You should also familiarize yourself with ```RDS``` [pricing](https://aws.amazon.com/rds/pricing/) so that you don't get surprised by large invoices once you actually begin using these in production projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Troubleshooting RDS creation\n",
    "\n",
    "If you cannot create your database using the RDS service and instead see the error below, you will need to create a new VPC instead of using the default one. \n",
    "\n",
    "![vpc dns error](images/vpc-rds-error.png)\n",
    "\n",
    "\n",
    "To do this, scroll back up to the \"Connectivity\" section, and choose \"Create new VPC\" from the dropdown as shown in the image below:\n",
    "\n",
    "![create new vpc](images/create-new-vpc.png)\n",
    "\n",
    "At the bottom of the page, press \"Create Database\" again, and you should see a notification briefly at the top of the page that confirms a new VPC has been created, as in the image below. Take a note of the ID.\n",
    "\n",
    "![view vpc](images/view-vpc-id.png)\n",
    "\n",
    "You might now see another error, as follows. This is because the VPC created from the RDS console has no name.\n",
    "\n",
    "![vpc no name error](images/vpc-no-name-error.png)\n",
    "\n",
    "\n",
    "If this is the case, you need to name your VPC. From the \"Services\" dropdown at the top of the page, search for \"VPC\" and open the VPC page in a new tab.\n",
    "\n",
    "\n",
    "![view VPCs](images/services-select-vpc.png)\n",
    "\n",
    "Find the VPC that was recently created (it will have the same ID as the one you noted above). Mouse over the \"Name\" field to see the pencil edit option appear, click on this, and give the VPC a name.\n",
    "\n",
    "\n",
    "![name VPC](images/name-vpc.png)\n",
    "\n",
    "Now that your VPC has a name, go back to the tab where you are creating the RDS instance, scroll back up to the \"Connectivity\" section, and choose the newly created VPC (you will see the name you chose displayed) from the dropdown.\n",
    "\n",
    "Now you can finally press \"Create Database\" again (at the bottom of the page) and all should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
